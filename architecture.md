# HybridPipeline Architecture

## ê°œìš”

### í”„ë¡œì íŠ¸ ëª©ì 

HybridPipelineì€ ì‹¤ì‹œê°„ 3D ì¥ë©´ ë Œë”ë§ì„ ìœ„í•œ ëª¨ë“ˆí™”ëœ íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.

**í•µì‹¬ ëª©í‘œ:**
- ğŸ¯ **ë Œë”ëŸ¬ êµì²´ ê°€ëŠ¥**: 3DGS, 4DGS, NeRF ë“± ë‹¤ì–‘í•œ ë Œë”ëŸ¬ë¥¼ ì‰½ê²Œ êµì²´
- ğŸ”Œ **í”„ë¡œí† ì½œ ë…ë¦½ì„±**: WebSocket, FIFO ë“± ë‹¤ì–‘í•œ ì „ì†¡ í”„ë¡œí† ì½œ ì§€ì›
- ğŸ§© **ëª¨ë“ˆí™”**: ë Œë”ë§, ì¸ì½”ë”©, ì „ì†¡ ë¡œì§ì˜ ëª…í™•í•œ ë¶„ë¦¬
- âš¡ **ê³ ì„±ëŠ¥**: Unix Socket ê¸°ë°˜ ì €ì§€ì—° í†µì‹ 

**ë¬¸ì œì :**
ê¸°ì¡´ ì½”ë“œëŠ” ë Œë”ë§ ë¡œì§ê³¼ ì „ì†¡ ë¡œì§ì´ í˜¼ì¬ë˜ì–´ ìˆì–´ ë Œë”ëŸ¬ êµì²´ê°€ ì–´ë µê³ , ë¶ˆí•„ìš”í•œ ê¸°ëŠ¥ì´ ë§ì•„ ìœ ì§€ë³´ìˆ˜ê°€ í˜ë“­ë‹ˆë‹¤.

**í•´ê²°ì±…:**
Transport Serviceì™€ Renderer Serviceë¥¼ ë¶„ë¦¬í•˜ê³ , ê° ì„œë¹„ìŠ¤ ë‚´ë¶€ë¥¼ ëª¨ë“ˆí™”í•˜ì—¬ í™•ì¥ ê°€ëŠ¥í•˜ê³  ìœ ì§€ë³´ìˆ˜ê°€ ì‰¬ìš´ ì•„í‚¤í…ì²˜ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.

---

## ì‹œìŠ¤í…œ êµ¬ì¡°

### ì„œë¹„ìŠ¤ êµ¬ì„±

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend        â”‚  ë¸Œë¼ìš°ì €/ì•± (TypeScript)
â”‚ Service         â”‚  - Three.js ë Œë”ë§
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - ì¹´ë©”ë¼ ì œì–´
         â”‚
         â”‚ WebSocket (Camera Data)
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Transport       â”‚  Python/asyncio
â”‚ Service         â”‚  - Frontend â†” Renderer ë¸Œë¦¿ì§€
â”‚                 â”‚  - í”„ë¡œí† ì½œ ë³€í™˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - ì—¬ëŸ¬ í”„ë¡œí† ì½œ ì§€ì›
         â”‚
         â”‚ Unix Socket (IPC)
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Renderer        â”‚  Python/PyTorch/CUDA
â”‚ Service         â”‚  - ì¥ë©´ ë Œë”ë§
â”‚                 â”‚  - ë°ì´í„° ì¸ì½”ë”©
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - ë Œë”ëŸ¬ êµì²´ ê°€ëŠ¥
```

### 1. Frontend Service

ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ë° ì¹´ë©”ë¼ ì œì–´:
- Three.js ê¸°ë°˜ 3D ë·°ì–´
- ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„° ìƒì„± (view matrix, intrinsics)
- WebSocketìœ¼ë¡œ Transportì™€ í†µì‹ 

### 2. Transport Service

Frontendì™€ Rendererë¥¼ ì—°ê²°í•˜ëŠ” **ìˆœìˆ˜ ë¸Œë¦¿ì§€**:
- âœ… ë°ì´í„° ì „ë‹¬ë§Œ ìˆ˜í–‰ (ë Œë”ë§ X)
- âœ… í”„ë¡œí† ì½œ ë³€í™˜ (WebSocket â†” Unix Socket)
- âœ… ì—¬ëŸ¬ Frontend í´ë¼ì´ì–¸íŠ¸ ë™ì‹œ ì§€ì›
- âœ… ì—¬ëŸ¬ í”„ë¡œí† ì½œ ë™ì‹œ ì§€ì› (WebSocket, FIFO)

**ì—­í• :**
- Frontend â†’ Renderer: Camera ë°ì´í„° ì „ë‹¬
- Renderer â†’ Frontend: ë Œë”ë§ ê²°ê³¼ ì „ë‹¬
- íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€/ê´€ë¦¬

### 3. Renderer Service

ì‹¤ì œ ë Œë”ë§ ìˆ˜í–‰:
- âœ… **Scene Renderer**: ì¥ë©´ ë Œë”ë§ (3DGS, 4DGS, NeRF ë“±)
- âœ… **Output Encoder**: ë°ì´í„° í¬ë§· ë³€í™˜ (JPEG, H.264, Raw)
- âœ… **Hook ì‹œìŠ¤í…œ**: ì´ˆê¸°í™”, ë Œë”ë§, ì¢…ë£Œ Hook
- âœ… **ë Œë”ëŸ¬ êµì²´ ê°€ëŠ¥**: git cloneìœ¼ë¡œ ìƒˆ ë Œë”ëŸ¬ ì¶”ê°€

---

## ë°ì´í„° íƒ€ì…

### CameraFrame

ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„° (Frontend â†’ Transport â†’ Renderer):

```python
class CameraFrame:
    view_matrix: np.ndarray    # (4, 4) float32 - Camera view matrix
    intrinsics: np.ndarray     # (4, 4) float32 - Camera intrinsics
    time_index: float          # Temporal index (for 4DGS)
    frame_id: int              # Frame identifier
    client_timestamp: float    # Client send time (ms)
    server_timestamp: float    # Server receive time (ms)
```

### RenderOutput

ë Œë”ë§ ê²°ê³¼ (ì¸ì½”ë”© ì „, Scene Renderer â†’ Encoder):

```python
class RenderOutput:
    color: torch.Tensor        # (H, W, 3) RGB float32 [0, 1]
    depth: torch.Tensor        # (H, W) float32
    alpha: torch.Tensor        # (H, W) float32 [0, 1]
    metadata: dict             # ì¶”ê°€ ë©”íƒ€ë°ì´í„°
```

### RenderPayload

ì¸ì½”ë”©ëœ ìµœì¢… ê²°ê³¼ (Encoder â†’ Transport â†’ Frontend):

```python
class RenderPayload:
    frame_id: int              # Frame identifier
    metadata: dict             # Format-specific metadata
    data: bytes                # Encoded payload (opaque)
```

**Metadata ì˜ˆì‹œ:**

JPEG + Depth:
```json
{
  "format_type": "jpeg+depth",
  "color_len": 12345,
  "depth_len": 67890,
  "depth_encoding": "float16",
  "width": 1280,
  "height": 720
}
```

H.264:
```json
{
  "format_type": "h264",
  "codec": "h264",
  "width": 1280,
  "height": 1440
}
```

---

## ë°ì´í„° íë¦„

### ì „ì²´ íë¦„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ 1. Camera Data (WebSocket)
         â”‚    - view_matrix, intrinsics, time_index
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Transport Service           â”‚
â”‚                             â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Frontend Adapters       â”‚ â”‚
â”‚ â”‚ - WebSocketAdapter      â”‚ â”‚  2. Camera Data ìˆ˜ì‹ 
â”‚ â”‚ - FIFOAdapter           â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚             â”‚                â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Transport Core          â”‚ â”‚  3. Camera Queueì— ì¶”ê°€
â”‚ â”‚ - Camera Queue          â”‚ â”‚
â”‚ â”‚ - Renderer í†µì‹          â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ 4. Camera Data (Unix Socket)
              â”‚    /run/ipc/camera.sock
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Renderer Service            â”‚
â”‚                             â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Camera Receive Loop     â”‚ â”‚  5. Camera Data ìˆ˜ì‹ 
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚             â”‚                â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Scene Renderer          â”‚ â”‚  6. ì¥ë©´ ë Œë”ë§
â”‚ â”‚ (3DGS/4DGS/NeRF)        â”‚ â”‚     â†’ RenderOutput
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚             â”‚                â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Output Encoder          â”‚ â”‚  7. ì¸ì½”ë”©
â”‚ â”‚ (JPEG/H264/Raw)         â”‚ â”‚     â†’ RenderPayload
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ 8. RenderPayload (Unix Socket)
              â”‚    /run/ipc/video.sock
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Transport Service           â”‚  9. Payload ìˆ˜ì‹ 
â”‚ - Broadcast to all clients  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ 10. Encoded data (WebSocket)
              â”‚     - JPEG+Depth or H.264
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend        â”‚  11. ë””ì½”ë”© ë° ë Œë”ë§
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ì‹¤í–‰ íë¦„

#### 1. ì´ˆê¸°í™” ë‹¨ê³„

```
Transport Service ì‹œì‘
    â†“
Unix Socket ë¦¬ìŠ¤ë‹ ì‹œì‘
(/run/ipc/camera.sock, /run/ipc/video.sock)
    â†“
Renderer Service ì‹œì‘
    â†“
Rendererê°€ Unix Socket ì—°ê²°
    â†“
Renderer: on_init() ì‹¤í–‰
- Scene ë¡œë“œ
- GPU ì—…ë¡œë“œ
- Encoder ì´ˆê¸°í™”
    â†“
Transportì— ì´ˆê¸°í™” ì™„ë£Œ ì‹ í˜¸ (handshake)
    â†“
Transport: Frontend ì—°ê²° ëŒ€ê¸° (WebSocket)
    â†“
ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ
```

#### 2. ë Œë”ë§ ë£¨í”„

```
Frontend: Camera ë°ì´í„° ìƒì„±
    â†“
WebSocketìœ¼ë¡œ Transportì— ì „ì†¡
    â†“
Transport: Camera Queueì— ì¶”ê°€
    â†“
Transport: Unix Socketìœ¼ë¡œ Rendererì— ì „ì†¡
    â†“
Renderer: Camera ë°ì´í„° ìˆ˜ì‹ 
    â†“
Scene Renderer: render(camera) ì‹¤í–‰
    â†“
Output Encoder: encode(render_output) ì‹¤í–‰
    â†“
Renderer: RenderPayloadë¥¼ Unix Socketìœ¼ë¡œ ì „ì†¡
    â†“
Transport: Payload ìˆ˜ì‹ 
    â†“
Transport: ëª¨ë“  ì—°ê²°ëœ Frontendì— ë¸Œë¡œë“œìºìŠ¤íŠ¸
    â†“
Frontend: ë””ì½”ë”© ë° í™”ë©´ ë Œë”ë§
    â†“
(ë°˜ë³µ)
```

#### 3. ì¢…ë£Œ ë‹¨ê³„

```
Frontend ì—°ê²° ì¢…ë£Œ
    â†“
Transport: Rendererì— ì¢…ë£Œ ì‹ í˜¸
    â†“
Renderer: on_shutdown() ì‹¤í–‰
- GPU ë©”ëª¨ë¦¬ í•´ì œ
- ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    â†“
Unix Socket ì—°ê²° ì¢…ë£Œ
    â†“
Transport Service ì¢…ë£Œ
```

---

## í´ë˜ìŠ¤ êµ¬ì¡°

### Renderer Service

#### 1. BaseSceneRenderer (ì¶”ìƒ í´ë˜ìŠ¤)

ì¥ë©´ ë Œë”ë§ ì¸í„°í˜ì´ìŠ¤:

```python
class BaseSceneRenderer:
    """Scene ë Œë”ë§ ì¶”ìƒ í´ë˜ìŠ¤"""

    async def on_init(self) -> bool:
        """
        ë Œë”ëŸ¬ ì´ˆê¸°í™” Hook
        - Scene ë¡œë“œ
        - GPU ì—…ë¡œë“œ
        - ëª¨ë¸ ì¤€ë¹„
        Returns: ì„±ê³µ ì—¬ë¶€
        """
        raise NotImplementedError

    async def render(self, camera: CameraFrame) -> RenderOutput:
        """
        ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„°ë¡œ ë Œë”ë§ ìˆ˜í–‰
        Args:
            camera: ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„°
        Returns:
            RenderOutput(color, depth, alpha, metadata)
        """
        raise NotImplementedError

    async def on_shutdown(self):
        """
        ë Œë”ëŸ¬ ì¢…ë£Œ Hook
        - GPU ë©”ëª¨ë¦¬ í•´ì œ
        - ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        """
        raise NotImplementedError
```

**êµ¬í˜„ ì˜ˆì‹œ:**

```python
class GaussianSplattingRenderer(BaseSceneRenderer):
    """3D Gaussian Splatting ë Œë”ëŸ¬"""

    def __init__(self, ply_path: str):
        self.ply_path = ply_path
        self.scene = None

    async def on_init(self) -> bool:
        print(f"Loading Gaussian Scene from {self.ply_path}")

        # Scene ë¡œë“œ
        self.scene = GaussianScene(self.ply_path)
        self.scene.upload_to_gpu()

        # Pipeline ì„¤ì •
        self.pipe = PipelineParams()
        self.background = torch.tensor([0, 0, 0], dtype=torch.float32).cuda()

        print(f"Loaded {self.scene.get_xyz.shape[0]} Gaussians")
        return True

    async def render(self, camera: CameraFrame) -> RenderOutput:
        # View matrixì™€ intrinsicsë¡œ Camera ê°ì²´ ìƒì„±
        cam = create_camera(
            camera.view_matrix,
            camera.intrinsics,
            width=1280,
            height=720
        )

        # Gaussian Splatting ë Œë”ë§
        render_pkg = gaussian_render(
            cam,
            self.scene,
            self.pipe,
            self.background
        )

        return RenderOutput(
            color=render_pkg["render"],       # (3, H, W) â†’ (H, W, 3)
            depth=render_pkg["depth"],         # (1, H, W) â†’ (H, W)
            alpha=render_pkg["alpha"],         # (1, H, W) â†’ (H, W)
            metadata={"renderer": "3dgs"}
        )

    async def on_shutdown(self):
        del self.scene
        torch.cuda.empty_cache()
        print("Gaussian Scene unloaded")


class StreamableGaussianRenderer(BaseSceneRenderer):
    """3DGStream ë Œë”ëŸ¬ (NTC + 2-stage training)"""

    def __init__(self, ply_path: str, ntc_path: str, ntc_config: str):
        self.ply_path = ply_path
        self.ntc_path = ntc_path
        self.ntc_config = ntc_config

    async def on_init(self) -> bool:
        # Gaussian ë¡œë“œ
        self.gaussians = TemporalGaussianModel(sh_degree=1)
        self.gaussians.load_ply(self.ply_path)

        # NTC ëª¨ë¸ ë¡œë“œ
        with open(self.ntc_config) as f:
            ntc_conf = json.load(f)

        self.ntc = NeuralTransformationCache(...)
        self.ntc.load_state_dict(torch.load(self.ntc_path))
        self.ntc_optimizer = torch.optim.Adam(self.ntc.parameters(), lr=0.002)

        # State ê´€ë¦¬
        self.state_manager = GaussianStateManager()
        self.state_manager.save_state(0, self.gaussians)

        return True

    async def render(self, camera: CameraFrame) -> RenderOutput:
        # ì´ì „ í”„ë ˆì„ state ë³µì›
        if camera.frame_id > 0:
            self.gaussians = self.state_manager.load_state(camera.frame_id - 1)

        # Stage 1: NTC transformation
        for _ in range(50):
            self.gaussians.query_ntc()
            render_pkg = gaussian_render(...)
            loss = compute_loss(render_pkg, gt_image)
            loss.backward()
            self.ntc_optimizer.step()

        # Stage 2: Gaussian refinement
        self.gaussians.update_by_ntc()
        for _ in range(50):
            render_pkg = gaussian_render(...)
            loss = compute_loss(...)
            loss.backward()
            self.gaussians.optimizer.step()

        # í˜„ì¬ í”„ë ˆì„ state ì €ì¥
        self.state_manager.save_state(camera.frame_id, self.gaussians)

        return RenderOutput(
            color=render_pkg["render"],
            depth=render_pkg["depth"],
            alpha=render_pkg["alpha"],
            metadata={"renderer": "3dgstream"}
        )
```

**ì™¸ë¶€ ë Œë”ëŸ¬ ì¶”ê°€ ë°©ë²•:**

```bash
# ìƒˆë¡œìš´ ë Œë”ëŸ¬ë¥¼ git cloneìœ¼ë¡œ ì¶”ê°€
cd renderer/scene_renderers/
git clone https://github.com/user/custom-renderer.git

# Wrapper í´ë˜ìŠ¤ ì‘ì„±
# custom_renderer_wrapper.py
from .custom_renderer import CustomRenderer as _CustomRenderer

class CustomRenderer(BaseSceneRenderer):
    def __init__(self):
        self.renderer = _CustomRenderer()

    async def on_init(self) -> bool:
        return self.renderer.init()

    async def render(self, camera: CameraFrame) -> RenderOutput:
        result = self.renderer.render(camera)
        return RenderOutput(color=result.color, ...)
```

#### 2. BaseEncoder (ì¶”ìƒ í´ë˜ìŠ¤)

ì¶œë ¥ í¬ë§· ì¸ì½”ë”© ì¸í„°í˜ì´ìŠ¤:

```python
class BaseEncoder:
    """ì¶œë ¥ ì¸ì½”ë” ì¶”ìƒ í´ë˜ìŠ¤"""

    def get_format_type(self) -> str:
        """í¬ë§· íƒ€ì… ë°˜í™˜ (ì˜ˆ: 'jpeg+depth', 'h264')"""
        raise NotImplementedError

    async def encode(self, output: RenderOutput, frame_id: int) -> RenderPayload:
        """
        RenderOutput â†’ RenderPayload ë³€í™˜
        Args:
            output: ë Œë”ë§ ê²°ê³¼
            frame_id: í”„ë ˆì„ ID
        Returns:
            RenderPayload (metadata + data)
        """
        raise NotImplementedError
```

**êµ¬í˜„ ì˜ˆì‹œ:**

```python
class JPEGEncoder(BaseEncoder):
    """JPEG + Float16 Depth Encoder"""

    def get_format_type(self) -> str:
        return "jpeg+depth"

    async def encode(self, output: RenderOutput, frame_id: int) -> RenderPayload:
        # Color â†’ JPEG
        color_uint8 = (output.color * 255).clamp(0, 255).to(torch.uint8)
        color_np = color_uint8.cpu().numpy()

        _, color_jpeg = cv2.imencode('.jpg',
            cv2.cvtColor(color_np, cv2.COLOR_RGB2BGR),
            [cv2.IMWRITE_JPEG_QUALITY, 90])
        color_bytes = color_jpeg.tobytes()

        # Depth â†’ Float16
        depth_normalized = normalize_depth(output.depth, output.alpha)
        depth_f16 = depth_normalized.to(torch.float16)
        depth_bytes = depth_f16.cpu().numpy().tobytes()

        return RenderPayload(
            frame_id=frame_id,
            metadata={
                "format_type": "jpeg+depth",
                "color_len": len(color_bytes),
                "depth_len": len(depth_bytes),
                "width": output.color.shape[1],
                "height": output.color.shape[0]
            },
            data=color_bytes + depth_bytes
        )


class H264Encoder(BaseEncoder):
    """H.264 Video Stream Encoder (color + depth combined)"""

    def __init__(self, width: int, height: int):
        import PyNvVideoCodec as nvvc

        self.width = width
        self.height = height

        # H.264 ì¸ì½”ë” ìƒì„± (combined height)
        self.encoder = nvvc.CreateEncoder(
            width=width,
            height=height * 2,  # color + depth vertically stacked
            fmt="NV12",
            codec="h264",
            preset="P3",
            bitrate=20000000,
            constqp=0,
            gop=1,
            fps=60,
            usecpuinputbuffer=False
        )

    def get_format_type(self) -> str:
        return "h264"

    async def encode(self, output: RenderOutput, frame_id: int) -> RenderPayload:
        # Color RGB â†’ uint8
        color_uint8 = (output.color * 255).clamp(0, 255).to(torch.uint8)

        # Depth â†’ 8bit visualization
        depth_vis = depth_to_8bit(output.depth, output.alpha)
        depth_rgb = depth_vis.unsqueeze(-1).expand(-1, -1, 3)

        # Vertical stack: [color, depth]
        combined = torch.cat([color_uint8, depth_rgb], dim=0)

        # RGB â†’ NV12
        nv12 = rgb_to_nv12(combined)

        # H.264 ì¸ì½”ë”©
        h264_bitstream = bytes(self.encoder.Encode(nv12))

        return RenderPayload(
            frame_id=frame_id,
            metadata={
                "format_type": "h264",
                "codec": "h264",
                "width": self.width,
                "height": self.height * 2
            },
            data=h264_bitstream
        )


class RawEncoder(BaseEncoder):
    """Raw tensor data (ë””ë²„ê¹…ìš©)"""

    def get_format_type(self) -> str:
        return "raw"

    async def encode(self, output: RenderOutput, frame_id: int) -> RenderPayload:
        import pickle

        data = {
            "color": output.color.cpu().numpy(),
            "depth": output.depth.cpu().numpy(),
            "alpha": output.alpha.cpu().numpy()
        }

        serialized = pickle.dumps(data)

        return RenderPayload(
            frame_id=frame_id,
            metadata={
                "format_type": "raw",
                "width": output.color.shape[1],
                "height": output.color.shape[0]
            },
            data=serialized
        )
```

#### 3. RendererService (ì¡°í•©)

Scene Rendererì™€ Encoderë¥¼ ì¡°í•©:

```python
class RendererService:
    """Renderer + Encoder ì¡°í•© ì„œë¹„ìŠ¤"""

    def __init__(self,
                 scene_renderer: BaseSceneRenderer,
                 encoder: BaseEncoder,
                 camera_socket: str = "/run/ipc/camera.sock",
                 video_socket: str = "/run/ipc/video.sock"):
        self.scene_renderer = scene_renderer
        self.encoder = encoder
        self.camera_socket = camera_socket
        self.video_socket = video_socket

    async def initialize(self) -> bool:
        """ì´ˆê¸°í™”"""
        # Renderer ì´ˆê¸°í™”
        success = await self.scene_renderer.on_init()
        if not success:
            return False

        # Unix Socket ì—°ê²°
        await self.connect_to_transport()

        return True

    async def connect_to_transport(self):
        """Transport Serviceì— ì—°ê²°"""
        # Camera data ìˆ˜ì‹ ìš©
        self.camera_reader, self.camera_writer = \
            await asyncio.open_unix_connection(self.camera_socket)

        # Video data ì†¡ì‹ ìš©
        self.video_reader, self.video_writer = \
            await asyncio.open_unix_connection(self.video_socket)

        print(f"Connected to Transport Service")

    async def camera_receive_loop(self, camera_queue: asyncio.Queue):
        """Camera ë°ì´í„° ìˆ˜ì‹ """
        while True:
            # 152 bytes ìˆ˜ì‹ 
            packet = await self.camera_reader.read(152)

            if len(packet) < 152:
                print("Incomplete camera packet")
                break

            camera = parse_camera_frame(packet)
            await camera_queue.put(camera)

    async def render_and_send_loop(self, camera_queue: asyncio.Queue):
        """ë Œë”ë§ ë° ì „ì†¡"""
        while True:
            # Camera ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            camera = await camera_queue.get()

            # 1. ì¥ë©´ ë Œë”ë§
            render_output = await self.scene_renderer.render(camera)

            # 2. ì¸ì½”ë”©
            payload = await self.encoder.encode(
                render_output,
                camera.frame_id
            )

            # 3. Wire formatìœ¼ë¡œ ì „ì†¡
            await self.send_payload(payload)

            camera_queue.task_done()

    async def send_payload(self, payload: RenderPayload):
        """RenderPayloadë¥¼ Transportë¡œ ì „ì†¡"""
        # Metadataë¥¼ JSONìœ¼ë¡œ ì§ë ¬í™”
        metadata_bytes = json.dumps(payload.metadata).encode('utf-8')

        # Header: frame_id(8) + metadata_len(4) + data_len(4)
        header = struct.pack("<QII",
            payload.frame_id,
            len(metadata_bytes),
            len(payload.data)
        )

        # ì „ì†¡
        self.video_writer.write(header + metadata_bytes + payload.data)
        await self.video_writer.drain()

    async def run(self):
        """ë©”ì¸ ë£¨í”„"""
        camera_queue = asyncio.Queue(maxsize=2)

        # ì´ˆê¸°í™”
        if not await self.initialize():
            print("Failed to initialize renderer")
            return

        # ë™ì‹œ ì‹¤í–‰
        await asyncio.gather(
            self.camera_receive_loop(camera_queue),
            self.render_and_send_loop(camera_queue)
        )

    async def shutdown(self):
        """ì¢…ë£Œ"""
        await self.scene_renderer.on_shutdown()
        self.camera_writer.close()
        self.video_writer.close()
```

**ì‚¬ìš© ì˜ˆì‹œ:**

```python
# main.py

# 3DGS + JPEG
renderer = RendererService(
    scene_renderer=GaussianSplattingRenderer(ply_path="scene.ply"),
    encoder=JPEGEncoder()
)

# 3DGS + H.264
renderer = RendererService(
    scene_renderer=GaussianSplattingRenderer(ply_path="scene.ply"),
    encoder=H264Encoder(width=1280, height=720)
)

# 3DGStream + JPEG
renderer = RendererService(
    scene_renderer=StreamableGaussianRenderer(
        ply_path="frame000000.ply",
        ntc_path="ntc_model.pth",
        ntc_config="ntc_config.json"
    ),
    encoder=JPEGEncoder()
)

# ì‹¤í–‰
asyncio.run(renderer.run())
```

### Transport Service

#### 1. TransportCore

í”„ë¡œí† ì½œ ë…ë¦½ì ì¸ í•µì‹¬ ë¡œì§:

```python
class TransportCore:
    """Transport í•µì‹¬ ë¡œì§ (í”„ë¡œí† ì½œ ë…ë¦½ì )"""

    def __init__(self,
                 camera_socket: str = "/run/ipc/camera.sock",
                 video_socket: str = "/run/ipc/video.sock"):
        self.camera_socket = camera_socket
        self.video_socket = video_socket

        # Renderer ì—°ê²°
        self.camera_writer = None
        self.video_reader = None

        # Frontend adapters
        self.frontend_adapters: List[BaseFrontendAdapter] = []

        # Camera queue (Frontend â†’ Renderer)
        self.camera_queue = asyncio.Queue(maxsize=2)

    async def start_renderer_listener(self):
        """Renderer ì—°ê²° ëŒ€ê¸° (Unix Socket Server)"""
        # Camera socket (Transport â†’ Renderer)
        camera_server = await asyncio.start_unix_server(
            self.handle_camera_connection,
            self.camera_socket
        )

        # Video socket (Renderer â†’ Transport)
        video_server = await asyncio.start_unix_server(
            self.handle_video_connection,
            self.video_socket
        )

        print(f"Listening for Renderer on {self.camera_socket}")
        print(f"Listening for Renderer on {self.video_socket}")

        await asyncio.gather(
            camera_server.serve_forever(),
            video_server.serve_forever()
        )

    async def handle_camera_connection(self, reader, writer):
        """Camera socket ì—°ê²° ì²˜ë¦¬"""
        print("Renderer connected to camera socket")
        self.camera_writer = writer

        # Camera ì „ì†¡ ë£¨í”„
        await self.camera_send_loop()

    async def handle_video_connection(self, reader, writer):
        """Video socket ì—°ê²° ì²˜ë¦¬"""
        print("Renderer connected to video socket")
        self.video_reader = reader

        # Video ìˆ˜ì‹  ë£¨í”„
        await self.video_receive_loop()

    async def camera_send_loop(self):
        """Frontend â†’ Rendererë¡œ Camera ì „ì†¡"""
        while True:
            camera = await self.camera_queue.get()

            # CameraFrame â†’ bytes (152 bytes)
            data = pack_camera_frame(camera)

            self.camera_writer.write(data)
            await self.camera_writer.drain()

            self.camera_queue.task_done()

    async def video_receive_loop(self):
        """Renderer â†’ Frontendë¡œ Video ì „ì†¡"""
        while True:
            # Wire format íŒŒì‹±
            header = await read_exact(self.video_reader, 16)
            frame_id, meta_len, data_len = struct.unpack("<QII", header)

            metadata_bytes = await read_exact(self.video_reader, meta_len)
            data = await read_exact(self.video_reader, data_len)

            metadata = json.loads(metadata_bytes)

            payload = RenderPayload(
                frame_id=frame_id,
                metadata=metadata,
                data=data
            )

            # ëª¨ë“  Frontendì— ë¸Œë¡œë“œìºìŠ¤íŠ¸
            await self.broadcast_to_frontends(payload)

    async def broadcast_to_frontends(self, payload: RenderPayload):
        """ëª¨ë“  ì—°ê²°ëœ Frontendì— ì „ì†¡"""
        for adapter in self.frontend_adapters:
            try:
                await adapter.send(payload)
            except Exception as e:
                print(f"Failed to send to frontend: {e}")

    def add_frontend_adapter(self, adapter: 'BaseFrontendAdapter'):
        """Frontend adapter ì¶”ê°€"""
        self.frontend_adapters.append(adapter)

    def remove_frontend_adapter(self, adapter: 'BaseFrontendAdapter'):
        """Frontend adapter ì œê±°"""
        self.frontend_adapters.remove(adapter)
```

#### 2. BaseFrontendAdapter (ì¶”ìƒ í´ë˜ìŠ¤)

Frontend í”„ë¡œí† ì½œ ì–´ëŒ‘í„°:

```python
class BaseFrontendAdapter:
    """Frontend í”„ë¡œí† ì½œ ì–´ëŒ‘í„° ì¶”ìƒ í´ë˜ìŠ¤"""

    async def send(self, payload: RenderPayload):
        """Frontendë¡œ ë Œë”ë§ ê²°ê³¼ ì „ì†¡"""
        raise NotImplementedError

    async def recv(self) -> CameraFrame:
        """Frontendì—ì„œ ì¹´ë©”ë¼ ë°ì´í„° ìˆ˜ì‹ """
        raise NotImplementedError
```

**êµ¬í˜„ ì˜ˆì‹œ:**

```python
class WebSocketAdapter(BaseFrontendAdapter):
    """WebSocket í”„ë¡œí† ì½œ ì–´ëŒ‘í„°"""

    def __init__(self, ws: websockets.WebSocketServerProtocol,
                 transport_core: TransportCore):
        self.ws = ws
        self.transport_core = transport_core

    async def send(self, payload: RenderPayload):
        """RenderPayload â†’ WebSocket í”„ë¡œí† ì½œ"""
        now = time.time_ns() / 1_000_000  # ms

        if payload.metadata["format_type"] == "h264":
            # H.264 í—¤ë” í˜•ì‹
            header = struct.pack("<IIdddd",
                len(payload.data),           # videoLen
                payload.frame_id,            # frameId
                0.0,                         # clientSendTime
                0.0,                         # serverReceiveTime
                now,                         # serverProcessEndTime
                now                          # serverSendTime
            )
            await self.ws.send(header + payload.data)

        elif payload.metadata["format_type"] == "jpeg+depth":
            # JPEG + Depth í—¤ë” í˜•ì‹
            header = struct.pack("<IIIdddd",
                payload.metadata["color_len"],
                payload.metadata["depth_len"],
                payload.frame_id,
                0.0,                         # clientSendTime
                0.0,                         # serverReceiveTime
                now,                         # serverProcessEndTime
                now                          # serverSendTime
            )
            await self.ws.send(header + payload.data)

    async def recv(self) -> CameraFrame:
        """WebSocket â†’ CameraFrame"""
        raw = await self.ws.recv()

        # Ping/Pong ì²˜ë¦¬
        if len(raw) == 16:
            # Ping message
            return None

        # Camera data (160 bytes)
        if len(raw) == 160:
            frame_id = struct.unpack_from("<I", raw, 128)[0]
            client_ts = struct.unpack_from("<d", raw, 136)[0]
            server_ts = time.time_ns() / 1_000_000
            time_index = struct.unpack_from("<f", raw, 144)[0]

            payload = raw[:128]
            floats = struct.unpack("<32f", payload)

            view_matrix = np.array(floats[:16]).reshape(4, 4)
            intrinsics = np.array(floats[16:32]).reshape(4, 4)

            return CameraFrame(
                view_matrix=view_matrix,
                intrinsics=intrinsics,
                time_index=time_index,
                frame_id=frame_id,
                client_timestamp=client_ts,
                server_timestamp=server_ts
            )

    async def recv_loop(self):
        """Camera ìˆ˜ì‹  ë£¨í”„"""
        try:
            while True:
                camera = await self.recv()
                if camera:
                    await self.transport_core.camera_queue.put(camera)
        except websockets.exceptions.ConnectionClosed:
            print(f"WebSocket closed: {self.ws.remote_address}")
        finally:
            self.transport_core.remove_frontend_adapter(self)


class FIFOAdapter(BaseFrontendAdapter):
    """Named Pipe (FIFO) í”„ë¡œí† ì½œ ì–´ëŒ‘í„° (ì†¡ì‹  ì „ìš©)"""

    def __init__(self, fifo_path: str):
        self.fifo_path = fifo_path
        self.fifo = None

    async def send(self, payload: RenderPayload):
        """RenderPayload â†’ FIFO"""
        if not self.fifo:
            loop = asyncio.get_event_loop()
            self.fifo = await loop.run_in_executor(
                None, open, self.fifo_path, 'wb'
            )

        # FIFOëŠ” ê°„ë‹¨í•œ í—¤ë”ë§Œ
        header = struct.pack("<QI",
            payload.frame_id,
            len(payload.data)
        )

        await asyncio.get_event_loop().run_in_executor(
            None, self.fifo.write, header + payload.data
        )
        await asyncio.get_event_loop().run_in_executor(
            None, self.fifo.flush
        )

    async def recv(self) -> CameraFrame:
        """FIFOëŠ” ë‹¨ë°©í–¥ (ì†¡ì‹  ì „ìš©)"""
        raise NotImplementedError("FIFO adapter is send-only")
```

#### 3. Transport Service Main

```python
# transport/main.py

async def websocket_handler(ws: websockets.WebSocketServerProtocol,
                           transport_core: TransportCore):
    """WebSocket ì—°ê²° í•¸ë“¤ëŸ¬"""
    print(f"Frontend connected: {ws.remote_address}")

    # Handshake
    handshake = await ws.recv()
    if len(handshake) != 4:
        await ws.close()
        return

    width, height = struct.unpack("<HH", handshake)
    print(f"Frontend resolution: {width}x{height}")

    # Adapter ìƒì„± ë° ë“±ë¡
    adapter = WebSocketAdapter(ws, transport_core)
    transport_core.add_frontend_adapter(adapter)

    try:
        # Camera ìˆ˜ì‹  ë£¨í”„
        await adapter.recv_loop()
    finally:
        transport_core.remove_frontend_adapter(adapter)
        print(f"Frontend disconnected: {ws.remote_address}")


async def main():
    # Transport Core ìƒì„±
    transport_core = TransportCore()

    # Renderer listener ì‹œì‘
    renderer_task = asyncio.create_task(
        transport_core.start_renderer_listener()
    )

    # WebSocket ì„œë²„ ì‹œì‘
    async with websockets.serve(
        lambda ws: websocket_handler(ws, transport_core),
        "0.0.0.0",
        8765,
        max_size=None,
        ping_interval=None
    ):
        print("Transport Service started")
        print("  WebSocket: ws://0.0.0.0:8765")
        print("  Renderer: /run/ipc/*.sock")

        await renderer_task


if __name__ == "__main__":
    asyncio.run(main())
```

---

## í†µì‹  í”„ë¡œí† ì½œ

### Frontend â†” Transport (WebSocket)

#### Camera Data (Frontend â†’ Transport)

**í”„ë¡œí† ì½œ**: 160 bytes

| Offset | Size | Type    | Field              |
|--------|------|---------|--------------------|
| 0      | 64   | float32 | view_matrix (4Ã—4)  |
| 64     | 64   | float32 | intrinsics (4Ã—4)   |
| 128    | 4    | uint32  | frame_id           |
| 132    | 4    | -       | padding            |
| 136    | 8    | float64 | client_timestamp   |
| 144    | 4    | float32 | time_index         |
| 148    | 12   | -       | padding            |

#### Video Data (Transport â†’ Frontend)

**H.264 í”„ë¡œí† ì½œ**: 40 bytes header + data

| Offset | Size | Type    | Field                   |
|--------|------|---------|-------------------------|
| 0      | 4    | uint32  | video_len               |
| 4      | 4    | uint32  | frame_id                |
| 8      | 8    | float64 | client_send_time        |
| 16     | 8    | float64 | server_receive_time     |
| 24     | 8    | float64 | server_process_end_time |
| 32     | 8    | float64 | server_send_time        |
| 40     | var  | bytes   | h264_bitstream          |

**JPEG + Depth í”„ë¡œí† ì½œ**: 44 bytes header + data

| Offset | Size | Type    | Field                   |
|--------|------|---------|-------------------------|
| 0      | 4    | uint32  | jpeg_len                |
| 4      | 4    | uint32  | depth_len               |
| 8      | 4    | uint32  | frame_id                |
| 12     | 8    | float64 | client_send_time        |
| 20     | 8    | float64 | server_receive_time     |
| 28     | 8    | float64 | server_process_end_time |
| 36     | 8    | float64 | server_send_time        |
| 44     | var  | bytes   | jpeg_data               |
| var    | var  | bytes   | depth_data (float16)    |

### Transport â†” Renderer (Unix Socket)

#### Camera Frame (Transport â†’ Renderer)

**í”„ë¡œí† ì½œ**: 152 bytes

| Offset | Size | Type    | Field              |
|--------|------|---------|--------------------|
| 0      | 64   | float32 | view_matrix (4Ã—4)  |
| 64     | 64   | float32 | intrinsics (4Ã—4)   |
| 128    | 8    | float64 | client_timestamp   |
| 136    | 8    | float64 | server_timestamp   |
| 144    | 4    | float32 | time_index         |
| 148    | 4    | uint32  | frame_id           |

#### Render Payload (Renderer â†’ Transport)

**í”„ë¡œí† ì½œ**: 16 bytes header + metadata (JSON) + data

| Offset | Size | Type   | Field         |
|--------|------|--------|---------------|
| 0      | 8    | uint64 | frame_id      |
| 8      | 4    | uint32 | metadata_len  |
| 12     | 4    | uint32 | data_len      |
| 16     | var  | bytes  | metadata (JSON)|
| var    | var  | bytes  | data (opaque) |

---

## Docker êµ¬ì„±

### docker-compose.yml

```yaml
version: '3.8'

services:
  transport-service:
    build: ./transport
    container_name: hybrid-transport
    ports:
      - "8765:8765"  # WebSocket port
    volumes:
      - ipc-sockets:/run/ipc  # Unix socket ê³µìœ 
    networks:
      - hybrid-net
    depends_on:
      - renderer-service

  renderer-service:
    build: ./renderer
    container_name: hybrid-renderer
    volumes:
      - ipc-sockets:/run/ipc  # Unix socket ê³µìœ 
      - ./data:/data          # Scene data
    networks:
      - hybrid-net
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

volumes:
  ipc-sockets:  # Unix Socket ê³µìœ  ë³¼ë¥¨

networks:
  hybrid-net:
```

### Renderer Dockerfile

```dockerfile
# renderer/Dockerfile
FROM nvidia/cuda:12.1.0-devel-ubuntu22.04

# Python ë° ì˜ì¡´ì„± ì„¤ì¹˜
RUN apt-get update && apt-get install -y \
    python3.10 \
    python3-pip \
    git

# PyTorch ì„¤ì¹˜
RUN pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# í”„ë¡œì íŠ¸ ì˜ì¡´ì„±
COPY requirements.txt .
RUN pip3 install -r requirements.txt

# ì½”ë“œ ë³µì‚¬
COPY . /app
WORKDIR /app

# Unix socket ë””ë ‰í† ë¦¬ ìƒì„±
RUN mkdir -p /run/ipc

CMD ["python3", "main.py"]
```

### Transport Dockerfile

```dockerfile
# transport/Dockerfile
FROM python:3.10-slim

# ì˜ì¡´ì„± ì„¤ì¹˜
COPY requirements.txt .
RUN pip install -r requirements.txt

# ì½”ë“œ ë³µì‚¬
COPY . /app
WORKDIR /app

# Unix socket ë””ë ‰í† ë¦¬ ìƒì„±
RUN mkdir -p /run/ipc

CMD ["python3", "main.py"]
```

---

## ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
HybridPipeline/
â”œâ”€â”€ architecture.md              # ì´ ë¬¸ì„œ
â”‚
â”œâ”€â”€ frontend/                    # Frontend Service
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.ts
â”‚   â”‚   â”œâ”€â”€ scene-setup.ts
â”‚   â”‚   â””â”€â”€ decode-worker.ts
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ transport/                   # Transport Service
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ main.py                  # Entry point
â”‚   â”œâ”€â”€ transport_core.py        # TransportCore
â”‚   â”œâ”€â”€ frontend_adapters/
â”‚   â”‚   â”œâ”€â”€ base.py              # BaseFrontendAdapter
â”‚   â”‚   â”œâ”€â”€ websocket.py         # WebSocketAdapter
â”‚   â”‚   â””â”€â”€ fifo.py              # FIFOAdapter
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ protocol.py          # í”„ë¡œí† ì½œ íŒŒì‹± ìœ í‹¸
â”‚
â”œâ”€â”€ renderer/                    # Renderer Service
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ main.py                  # Entry point
â”‚   â”‚
â”‚   â”œâ”€â”€ scene_renderers/         # Scene Renderers
â”‚   â”‚   â”œâ”€â”€ base.py              # BaseSceneRenderer
â”‚   â”‚   â”œâ”€â”€ gaussian_splatting.py
â”‚   â”‚   â”œâ”€â”€ streamable_gaussian.py
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ external/            # git cloneìœ¼ë¡œ ì¶”ê°€ë˜ëŠ” ë Œë”ëŸ¬
â”‚   â”‚       â”œâ”€â”€ 3d-gaussian-splatting/  (git submodule)
â”‚   â”‚       â”œâ”€â”€ 3dgstream/              (git submodule)
â”‚   â”‚       â””â”€â”€ custom-renderer/        (git submodule)
â”‚   â”‚
â”‚   â”œâ”€â”€ encoders/                # Output Encoders
â”‚   â”‚   â”œâ”€â”€ base.py              # BaseEncoder
â”‚   â”‚   â”œâ”€â”€ jpeg.py              # JPEGEncoder
â”‚   â”‚   â”œâ”€â”€ h264.py              # H264Encoder
â”‚   â”‚   â””â”€â”€ raw.py               # RawEncoder
â”‚   â”‚
â”‚   â”œâ”€â”€ renderer_service.py      # RendererService
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ protocol.py          # í”„ë¡œí† ì½œ íŒŒì‹±
â”‚       â””â”€â”€ image_utils.py       # ì´ë¯¸ì§€ ë³€í™˜ ìœ í‹¸
â”‚
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

---

## ì„¤ê³„ ì›ì¹™

### 1. ê´€ì‹¬ì‚¬ì˜ ë¶„ë¦¬ (Separation of Concerns)

- **Scene Renderer**: ì¥ë©´ ë Œë”ë§ë§Œ ë‹´ë‹¹
- **Encoder**: ë°ì´í„° í¬ë§· ë³€í™˜ë§Œ ë‹´ë‹¹
- **Transport**: ë°ì´í„° ì „ë‹¬ë§Œ ë‹´ë‹¹ (ë Œë”ë§ X)

### 2. ì¡°í•© ê°€ëŠ¥ì„± (Composability)

ë Œë”ëŸ¬ì™€ ì¸ì½”ë”ë¥¼ ììœ ë¡­ê²Œ ì¡°í•©:

```python
# 3DGS + JPEG
GaussianSplattingRenderer + JPEGEncoder

# 3DGS + H.264
GaussianSplattingRenderer + H264Encoder

# 3DGStream + JPEG
StreamableGaussianRenderer + JPEGEncoder

# Custom + Raw
CustomRenderer + RawEncoder
```

### 3. í™•ì¥ ê°€ëŠ¥ì„± (Extensibility)

- **ìƒˆë¡œìš´ Scene Renderer ì¶”ê°€**: `BaseSceneRenderer` ìƒì†
- **ìƒˆë¡œìš´ Encoder ì¶”ê°€**: `BaseEncoder` ìƒì†
- **ìƒˆë¡œìš´ í”„ë¡œí† ì½œ ì¶”ê°€**: `BaseFrontendAdapter` ìƒì†

**ì™¸ë¶€ ë Œë”ëŸ¬ í†µí•©**:

```bash
# Git submoduleë¡œ ì¶”ê°€
cd renderer/scene_renderers/external/
git submodule add https://github.com/user/custom-renderer.git

# Wrapper ì‘ì„±
# renderer/scene_renderers/custom_wrapper.py
from .external.custom_renderer import Renderer as _CustomRenderer
from .base import BaseSceneRenderer

class CustomRenderer(BaseSceneRenderer):
    def __init__(self):
        self.renderer = _CustomRenderer()

    async def on_init(self) -> bool:
        return self.renderer.initialize()

    async def render(self, camera) -> RenderOutput:
        result = self.renderer.render(camera)
        return RenderOutput(color=result.rgb, depth=result.depth, ...)
```

### 4. í”„ë¡œí† ì½œ ë…ë¦½ì„± (Protocol Independence)

Transport CoreëŠ” Frontend í”„ë¡œí† ì½œê³¼ ë…ë¦½ì :
- WebSocket, FIFO ë“±ì„ Adapterë¡œ ì¶”ìƒí™”
- ì—¬ëŸ¬ í”„ë¡œí† ì½œ ë™ì‹œ ì§€ì› ê°€ëŠ¥

Transport â†” RendererëŠ” Unix Socket ê³ ì •:
- ê°™ì€ í˜¸ìŠ¤íŠ¸ í™˜ê²½ (Docker Volume Mount)
- ìµœê³  ì„±ëŠ¥ (40-50 GB/s)
- ê°„ë‹¨í•œ êµ¬í˜„

### 5. YAGNI (You Aren't Gonna Need It)

**Phase 1**: í•µì‹¬ ê¸°ëŠ¥ë§Œ êµ¬í˜„
- Unix Socketë§Œ ì§€ì›
- ê¸°ë³¸ ë Œë”ëŸ¬ (3DGS)
- ê¸°ë³¸ ì¸ì½”ë” (JPEG)

**Phase 2**: í•„ìš”ì‹œ í™•ì¥
- ì¶”ê°€ ë Œë”ëŸ¬ (3DGStream, NeRF)
- ì¶”ê°€ ì¸ì½”ë” (H.264, Raw)
- ì¶”ê°€ í”„ë¡œí† ì½œ (FIFO)

---

## êµ¬í˜„ ìš°ì„ ìˆœìœ„

### Phase 1: MVP (Minimum Viable Product)

1. **Renderer Service**
   - âœ… `BaseSceneRenderer` ì¶”ìƒ í´ë˜ìŠ¤
   - âœ… `GaussianSplattingRenderer` êµ¬í˜„
   - âœ… `JPEGEncoder` êµ¬í˜„
   - âœ… `RendererService` ì¡°í•©
   - âœ… Unix Socket í†µì‹ 

2. **Transport Service**
   - âœ… `TransportCore` êµ¬í˜„
   - âœ… `WebSocketAdapter` êµ¬í˜„
   - âœ… Unix Socket ì„œë²„

3. **í†µí•© í…ŒìŠ¤íŠ¸**
   - âœ… Frontend â†’ Transport â†’ Renderer ë°ì´í„° íë¦„
   - âœ… Docker Compose í™˜ê²½

### Phase 2: í™•ì¥ ê¸°ëŠ¥

1. **Encoder ì¶”ê°€**
   - `H264Encoder` êµ¬í˜„
   - `RawEncoder` êµ¬í˜„ (ë””ë²„ê¹…ìš©)

2. **Renderer ì¶”ê°€**
   - `StreamableGaussianRenderer` êµ¬í˜„ (3DGStream)

3. **í”„ë¡œí† ì½œ ì¶”ê°€**
   - `FIFOAdapter` êµ¬í˜„

### Phase 3: ìµœì í™”

1. **ì„±ëŠ¥ ìµœì í™”**
   - Zero-copy ì „ì†¡
   - Batch processing
   - GPU Direct ì „ì†¡

2. **ëª¨ë‹ˆí„°ë§**
   - ë ˆì´í„´ì‹œ ì¸¡ì •
   - FPS ëª¨ë‹ˆí„°ë§
   - ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰

---

## ê¸°ì¡´ ì½”ë“œ ë¬¸ì œì 

### 1. feed-forward-renderer-socket.py (807ì¤„)

**ë¬¸ì œì :**
- 3DGStream íŠ¹í™” ë¡œì§ (NTC, 2-stage training)ê³¼ ì¼ë°˜ ë Œë”ë§ í˜¼ì¬
- ë Œë”ëŸ¬ êµì²´ ë¶ˆê°€ëŠ¥í•œ êµ¬ì¡°
- H.264 ì¸ì½”ë”© ë¡œì§ì´ ë Œë”ë§ ë¡œì§ê³¼ ì„ì—¬ìˆìŒ
- State ê´€ë¦¬, training ë¡œì§ì´ ë³µì¡í•˜ê²Œ ì–½í˜€ìˆìŒ

**ê°œì„ :**
- Scene Rendererì™€ Encoder ë¶„ë¦¬
- `StreamableGaussianRenderer`ë¡œ 3DGStream ë¡œì§ ìº¡ìŠí™”
- `H264Encoder`ë¡œ ì¸ì½”ë”© ë¡œì§ ë¶„ë¦¬

### 2. server.py

**ë¬¸ì œì :**
- Transport ì—­í•  + ë Œë”ë§ ì—­í•  í˜¼ì¬
- 3ê°€ì§€ ë Œë”ë§ ë£¨í”„ ì¤‘ë³µ (`render_loop`, `render_loop_jpeg`, `render_feedforward_loop`)
- WebSocketê³¼ FIFO í†µì‹  ë¡œì§ì´ í˜¼ì¬

**ê°œì„ :**
- TransportëŠ” ë°ì´í„° ì „ë‹¬ë§Œ ìˆ˜í–‰
- ë Œë”ë§ì€ Renderer Serviceë¡œ ì™„ì „ ë¶„ë¦¬
- Protocol Adapter íŒ¨í„´ìœ¼ë¡œ WebSocket/FIFO ì¶”ìƒí™”

### 3. session.py

**ë¬¸ì œì :**
- Encoder ìƒì„± ë¡œì§ì´ Sessionì— í¬í•¨
- ë¶ˆí•„ìš”í•œ ê²°í•©

**ê°œì„ :**
- EncoderëŠ” Renderer Serviceì—ì„œë§Œ ê´€ë¦¬
- TransportëŠ” Encoderì— ëŒ€í•´ ì•Œ í•„ìš” ì—†ìŒ

---

## ì°¸ê³  ìë£Œ

### í”„ë¡œí† ì½œ ì„¤ê³„

- WebSocket: RFC 6455
- Unix Socket: POSIX IPC
- H.264: ITU-T H.264 / MPEG-4 AVC

### ë Œë”ë§ ì—”ì§„

- 3D Gaussian Splatting: https://github.com/graphdeco-inria/gaussian-splatting
- 3DGStream: (í”„ë¡œì íŠ¸ ë‚´ë¶€ êµ¬í˜„)
- diff-gaussian-rasterization: CUDA ê¸°ë°˜ rasterizer

### ì¸ì½”ë”©

- NVENC (H.264): PyNvVideoCodec
- JPEG: OpenCV, nvImageCodec
- Depth Encoding: Log-depth normalization

---

## ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ

ê¸°ì¡´ ì½”ë“œì—ì„œ ìƒˆ ì•„í‚¤í…ì²˜ë¡œ ì „í™˜:

### 1. feed-forward-renderer-socket.py â†’ Renderer Service

```python
# Before: 807ì¤„ì˜ ë³µì¡í•œ ì½”ë“œ

# After: ëª…í™•í•œ ë¶„ë¦¬
renderer = RendererService(
    scene_renderer=StreamableGaussianRenderer(...),
    encoder=H264Encoder(...)
)
```

### 2. server.py â†’ Transport Service

```python
# Before: ë Œë”ë§ + ì „ì†¡ í˜¼ì¬

# After: ì „ì†¡ë§Œ ìˆ˜í–‰
transport = TransportCore()
# ë Œë”ë§ì€ Renderer Serviceê°€ ë‹´ë‹¹
```

### 3. ìƒˆë¡œìš´ ë Œë”ëŸ¬ ì¶”ê°€

```bash
# Git submoduleë¡œ ì¶”ê°€
cd renderer/scene_renderers/external/
git submodule add https://github.com/user/nerf-renderer.git

# Wrapper ì‘ì„±
class NeRFRenderer(BaseSceneRenderer):
    async def render(self, camera):
        # NeRF ë Œë”ë§ ë¡œì§
        ...
```

---

## FAQ

### Q: ì™œ Transportì™€ Rendererë¥¼ ë¶„ë¦¬í•˜ë‚˜ìš”?

**A**: ê´€ì‹¬ì‚¬ì˜ ë¶„ë¦¬ì™€ ìœ ì—°ì„±ì„ ìœ„í•´ì„œì…ë‹ˆë‹¤.
- TransportëŠ” í”„ë¡œí† ì½œ ë³€í™˜ë§Œ ë‹´ë‹¹
- RendererëŠ” ë Œë”ë§ë§Œ ë‹´ë‹¹
- ë Œë”ëŸ¬ êµì²´ ì‹œ Transport ìˆ˜ì • ë¶ˆí•„ìš”
- ê° ì„œë¹„ìŠ¤ë¥¼ ë…ë¦½ì ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§ ê°€ëŠ¥

### Q: Unix Socket vs TCP Socket?

**A**: Docker í™˜ê²½ì—ì„œëŠ” Unix Socketì´ ìµœì ì…ë‹ˆë‹¤.
- Volume Mountë¡œ ì»¨í…Œì´ë„ˆ ê°„ ê³µìœ  ê°€ëŠ¥
- TCP ëŒ€ë¹„ 2ë°° ì´ìƒ ë¹ ë¦„ (40-50 GB/s)
- ê°„ë‹¨í•œ êµ¬í˜„
- ë¡œì»¬ í™˜ê²½ì—ì„œ ì¶©ë¶„

### Q: ìƒˆë¡œìš´ ë Œë”ëŸ¬ ì¶”ê°€ëŠ” ì–´ë–»ê²Œ í•˜ë‚˜ìš”?

**A**: Git submodule + Wrapper íŒ¨í„´:
```bash
git submodule add <repo-url> renderer/scene_renderers/external/my-renderer
```
ê·¸ë¦¬ê³  `BaseSceneRenderer`ë¥¼ ìƒì†í•˜ëŠ” Wrapper ì‘ì„±

### Q: JPEG vs H.264?

**A**: ìš©ë„ì— ë”°ë¼ ì„ íƒ:
- **JPEG**: í”„ë ˆì„ ë…ë¦½, ë””ë²„ê¹… ì‰¬ì›€, ì••ì¶•ë¥  ë‚®ìŒ
- **H.264**: ë†’ì€ ì••ì¶•ë¥ , ë³µì¡í•œ ë””ë²„ê¹…, ì‹œê°„ì  ì¢…ì†ì„±

### Q: ê¸°ì¡´ ì½”ë“œëŠ” ì‚­ì œí•˜ë‚˜ìš”?

**A**: ì•„ë‹ˆìš”, `research/` í´ë”ì— ë³´ê´€:
```
research/
â”œâ”€â”€ 3DGStream/
â”‚   â”œâ”€â”€ feed-forward-renderer-socket.py  # ì°¸ê³ ìš©
â”‚   â””â”€â”€ feed-forward-renderer.py
â””â”€â”€ backend/
    â””â”€â”€ src/
        â””â”€â”€ server.py  # ì°¸ê³ ìš©
```

---

## Renderer Service êµ¬í˜„ ì„¸ë¶€ì‚¬í•­

### í”„ë¡œí† ì½œ íŒŒì‹± êµ¬í˜„

#### Camera Frame íŒŒì‹± (152 bytes)

```python
# renderer/utils/protocol.py

import struct
import numpy as np
from data_types import CameraFrame

def parse_camera_frame(data: bytes) -> CameraFrame:
    """
    152 bytes â†’ CameraFrame ë³€í™˜

    Layout:
    0-64:     view_matrix (16 float32)
    64-128:   intrinsics (16 float32)
    128-136:  client_timestamp (float64)
    136-144:  server_timestamp (float64)
    144-148:  time_index (float32)
    148-152:  frame_id (uint32)
    """
    if len(data) != 152:
        raise ValueError(f"Invalid camera frame size: {len(data)} (expected 152)")

    # View matrix (64 bytes)
    view_floats = struct.unpack("<16f", data[0:64])
    view_matrix = np.array(view_floats, dtype=np.float32).reshape(4, 4)

    # Intrinsics (64 bytes)
    intrinsics_floats = struct.unpack("<16f", data[64:128])
    intrinsics = np.array(intrinsics_floats, dtype=np.float32).reshape(4, 4)

    # Metadata
    client_timestamp = struct.unpack("<d", data[128:136])[0]
    server_timestamp = struct.unpack("<d", data[136:144])[0]
    time_index = struct.unpack("<f", data[144:148])[0]
    frame_id = struct.unpack("<I", data[148:152])[0]

    return CameraFrame(
        view_matrix=view_matrix,
        intrinsics=intrinsics,
        time_index=time_index,
        frame_id=frame_id,
        client_timestamp=client_timestamp,
        server_timestamp=server_timestamp
    )


def pack_camera_frame(camera: CameraFrame) -> bytes:
    """CameraFrame â†’ 152 bytes ë³€í™˜ (Transportì—ì„œ ì‚¬ìš©)"""
    view_bytes = camera.view_matrix.astype(np.float32).tobytes()
    intrinsics_bytes = camera.intrinsics.astype(np.float32).tobytes()

    metadata_bytes = struct.pack("<ddfi",
        camera.client_timestamp,
        camera.server_timestamp,
        camera.time_index,
        camera.frame_id
    )

    return view_bytes + intrinsics_bytes + metadata_bytes
```

#### Render Payload íŒŒì‹± (16 + metadata + data)

```python
import json

def pack_render_payload(payload: RenderPayload) -> bytes:
    """
    RenderPayload â†’ Wire format

    Header (16 bytes):
    0-8:   frame_id (uint64)
    8-12:  metadata_len (uint32)
    12-16: data_len (uint32)

    Metadata: JSON bytes (UTF-8)
    Data: opaque bytes
    """
    metadata_bytes = json.dumps(payload.metadata).encode('utf-8')

    header = struct.pack("<QII",
        payload.frame_id,
        len(metadata_bytes),
        len(payload.data)
    )

    return header + metadata_bytes + payload.data


async def read_exact(reader: asyncio.StreamReader, n: int) -> bytes:
    """ì •í™•íˆ n bytes ì½ê¸° (incomplete ë°©ì§€)"""
    data = b""
    while len(data) < n:
        chunk = await reader.read(n - len(data))
        if not chunk:
            raise EOFError(f"Incomplete read: expected {n}, got {len(data)}")
        data += chunk
    return data


async def parse_render_payload(reader: asyncio.StreamReader) -> RenderPayload:
    """Wire format â†’ RenderPayload"""
    # Header ì½ê¸°
    header = await read_exact(reader, 16)
    frame_id, meta_len, data_len = struct.unpack("<QII", header)

    # Metadata ì½ê¸°
    metadata_bytes = await read_exact(reader, meta_len)
    metadata = json.loads(metadata_bytes.decode('utf-8'))

    # Data ì½ê¸°
    data = await read_exact(reader, data_len)

    return RenderPayload(
        frame_id=frame_id,
        metadata=metadata,
        data=data
    )
```

### ì—ëŸ¬ í•¸ë“¤ë§ ë° ë³µêµ¬ ì „ëµ

#### 1. Socket ì—°ê²° ì—ëŸ¬

```python
class RendererService:
    async def connect_to_transport(self, max_retries=5):
        """Transport Serviceì— ì—°ê²° (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
        for attempt in range(max_retries):
            try:
                # Camera socket ì—°ê²°
                self.camera_reader, self.camera_writer = \
                    await asyncio.open_unix_connection(self.camera_socket)

                # Video socket ì—°ê²°
                self.video_reader, self.video_writer = \
                    await asyncio.open_unix_connection(self.video_socket)

                print(f"âœ… Connected to Transport Service")
                return True

            except FileNotFoundError:
                if attempt < max_retries - 1:
                    wait_time = 2 ** attempt  # Exponential backoff
                    print(f"âš ï¸  Transport not ready, retrying in {wait_time}s...")
                    await asyncio.sleep(wait_time)
                else:
                    print(f"âŒ Failed to connect after {max_retries} attempts")
                    return False
            except Exception as e:
                print(f"âŒ Connection error: {e}")
                return False
```

#### 2. ë Œë”ë§ ì—ëŸ¬

```python
async def render_and_send_loop(self, camera_queue: asyncio.Queue):
    """ë Œë”ë§ ë° ì „ì†¡ (ì—ëŸ¬ ë³µêµ¬)"""
    while True:
        try:
            # Camera ê°€ì ¸ì˜¤ê¸°
            camera = await camera_queue.get()

            try:
                # 1. ì¥ë©´ ë Œë”ë§
                render_output = await self.scene_renderer.render(camera)

                # 2. ì¸ì½”ë”©
                payload = await self.encoder.encode(
                    render_output,
                    camera.frame_id
                )

                # 3. ì „ì†¡
                await self.send_payload(payload)

            except torch.cuda.OutOfMemoryError:
                # GPU OOM: ìºì‹œ ì •ë¦¬ í›„ ì¬ì‹œë„
                print(f"âš ï¸  GPU OOM at frame {camera.frame_id}, clearing cache...")
                torch.cuda.empty_cache()
                # í•´ë‹¹ í”„ë ˆì„ drop

            except Exception as e:
                # ê¸°íƒ€ ë Œë”ë§ ì—ëŸ¬: ë¡œê·¸ í›„ skip
                print(f"âŒ Render error at frame {camera.frame_id}: {e}")
                # í•´ë‹¹ í”„ë ˆì„ drop

            finally:
                camera_queue.task_done()

        except asyncio.CancelledError:
            print("Render loop cancelled")
            break
        except Exception as e:
            print(f"âŒ Fatal error in render loop: {e}")
            break
```

#### 3. ë°ì´í„° ê²€ì¦

```python
def validate_camera_frame(camera: CameraFrame) -> bool:
    """Camera ë°ì´í„° ê²€ì¦"""
    # View matrix ì²´í¬
    if camera.view_matrix.shape != (4, 4):
        print(f"âŒ Invalid view_matrix shape: {camera.view_matrix.shape}")
        return False

    # Intrinsics ì²´í¬
    if camera.intrinsics.shape != (4, 4):
        print(f"âŒ Invalid intrinsics shape: {camera.intrinsics.shape}")
        return False

    # Frame ID ì²´í¬
    if camera.frame_id < 0:
        print(f"âŒ Invalid frame_id: {camera.frame_id}")
        return False

    return True


def validate_render_output(output: RenderOutput, expected_size: tuple) -> bool:
    """RenderOutput ê²€ì¦"""
    H, W = expected_size

    # Shape ê²€ì¦
    if output.color.shape != (H, W, 3):
        print(f"âŒ Invalid color shape: {output.color.shape}, expected ({H}, {W}, 3)")
        return False

    if output.depth.shape != (H, W):
        print(f"âŒ Invalid depth shape: {output.depth.shape}, expected ({H}, {W})")
        return False

    # ê°’ ë²”ìœ„ ê²€ì¦
    if not (torch.all(output.color >= 0) and torch.all(output.color <= 1)):
        print(f"âš ï¸  Color values out of range [0, 1]")
        output.color = torch.clamp(output.color, 0, 1)

    if not (torch.all(output.alpha >= 0) and torch.all(output.alpha <= 1)):
        print(f"âš ï¸  Alpha values out of range [0, 1]")
        output.alpha = torch.clamp(output.alpha, 0, 1)

    return True
```

#### 4. Queue Overflow ì²˜ë¦¬

```python
async def handle_camera_with_overflow(self, camera_queue: asyncio.Queue, camera: CameraFrame):
    """Queue overflow ì²˜ë¦¬ (ì˜¤ë˜ëœ í”„ë ˆì„ drop)"""
    try:
        camera_queue.put_nowait(camera)
    except asyncio.QueueFull:
        # ê°€ì¥ ì˜¤ë˜ëœ í”„ë ˆì„ ì œê±°
        try:
            dropped = camera_queue.get_nowait()
            print(f"âš ï¸  Queue full, dropping frame {dropped.frame_id}")
        except asyncio.QueueEmpty:
            pass

        # ìƒˆ í”„ë ˆì„ ì¶”ê°€
        camera_queue.put_nowait(camera)
```

---

## ì„±ëŠ¥ ìµœì í™” ê°€ì´ë“œ

### 1. GPU ë©”ëª¨ë¦¬ ê´€ë¦¬

```python
class GaussianSplattingRenderer(BaseSceneRenderer):
    async def on_init(self) -> bool:
        # Scene ë¡œë“œ
        self.scene = GaussianScene(self.ply_path)

        # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
        total_memory = torch.cuda.get_device_properties(0).total_memory
        print(f"Total GPU memory: {total_memory / 1e9:.2f} GB")

        # Scene ì—…ë¡œë“œ
        self.scene.upload_to_gpu()

        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
        allocated = torch.cuda.memory_allocated() / 1e9
        reserved = torch.cuda.memory_reserved() / 1e9
        print(f"GPU memory: allocated={allocated:.2f}GB, reserved={reserved:.2f}GB")

        return True

    async def on_shutdown(self):
        # GPU ë©”ëª¨ë¦¬ í•´ì œ
        del self.scene
        torch.cuda.empty_cache()

        # í•´ì œ í™•ì¸
        allocated = torch.cuda.memory_allocated() / 1e9
        print(f"GPU memory after cleanup: {allocated:.2f}GB")
```

### 2. ë¹„ë™ê¸° ì²˜ë¦¬ ìµœì í™”

```python
class RendererService:
    async def run(self):
        """ìµœì í™”ëœ ë©”ì¸ ë£¨í”„"""
        # Queue í¬ê¸° ì¡°ì • (ë ˆì´í„´ì‹œ vs ì²˜ë¦¬ëŸ‰)
        camera_queue = asyncio.Queue(maxsize=2)  # ì‘ì„ìˆ˜ë¡ ë‚®ì€ ë ˆì´í„´ì‹œ

        # ë™ì‹œ ì²˜ë¦¬
        await asyncio.gather(
            self.camera_receive_loop(camera_queue),
            self.render_and_send_loop(camera_queue),
            # ì¶”ê°€ ì›Œì»¤ ê°€ëŠ¥ (ë‹¤ì¤‘ GPU í™˜ê²½)
            # self.render_and_send_loop(camera_queue),
        )
```

### 3. ì¸ì½”ë”© ìµœì í™”

```python
class JPEGEncoder(BaseEncoder):
    def __init__(self, quality=90, optimize_cpu=True):
        self.quality = quality
        self.optimize_cpu = optimize_cpu

        # JPEG ì¸ì½”ë” íŒŒë¼ë¯¸í„°
        self.encode_params = [
            cv2.IMWRITE_JPEG_QUALITY, quality,
            cv2.IMWRITE_JPEG_OPTIMIZE, 1 if optimize_cpu else 0,
            cv2.IMWRITE_JPEG_PROGRESSIVE, 0  # Progressive ë„ê¸° (ì†ë„ í–¥ìƒ)
        ]

    async def encode(self, output: RenderOutput, frame_id: int) -> RenderPayload:
        # GPU â†’ CPU ì „ì†¡ ìµœì†Œí™”
        color_uint8 = (output.color * 255).clamp(0, 255).to(torch.uint8)

        # CPUë¡œ ì´ë™ (í•œë²ˆë§Œ)
        color_np = color_uint8.cpu().numpy()

        # JPEG ì¸ì½”ë”© (OpenCVëŠ” CPUì—ì„œ ì‹¤í–‰)
        _, color_jpeg = cv2.imencode('.jpg',
            cv2.cvtColor(color_np, cv2.COLOR_RGB2BGR),
            self.encode_params)

        # DepthëŠ” GPUì—ì„œ float16 ë³€í™˜ í›„ CPUë¡œ
        depth_f16 = output.depth.to(torch.float16)
        depth_bytes = depth_f16.cpu().numpy().tobytes()

        # ...
```

### 4. Zero-Copy ì „ì†¡ (ê³ ê¸‰)

```python
# PyTorch Tensor â†’ Unix Socket ì§ì ‘ ì „ì†¡ (ì¤‘ê°„ ë³µì‚¬ ì œê±°)

async def send_payload_zerocopy(self, payload: RenderPayload):
    """Zero-copy ì „ì†¡ (memoryview ì‚¬ìš©)"""
    # Header
    header = struct.pack("<QII",
        payload.frame_id,
        len(payload.metadata),
        len(payload.data)
    )

    # Metadata
    metadata_bytes = json.dumps(payload.metadata).encode('utf-8')

    # Zero-copy write
    self.video_writer.write(header)
    self.video_writer.write(metadata_bytes)

    # Dataë¥¼ memoryviewë¡œ ì „ì†¡ (ë³µì‚¬ ì—†ìŒ)
    if isinstance(payload.data, bytes):
        self.video_writer.write(memoryview(payload.data))

    await self.video_writer.drain()
```

### 5. í”„ë¡œíŒŒì¼ë§

```python
import time

class ProfilingRendererService(RendererService):
    """ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ì´ í¬í•¨ëœ Renderer"""

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.metrics = {
            "render_times": [],
            "encode_times": [],
            "send_times": [],
            "total_times": []
        }

    async def render_and_send_loop(self, camera_queue: asyncio.Queue):
        while True:
            camera = await camera_queue.get()

            total_start = time.perf_counter()

            # 1. Render
            render_start = time.perf_counter()
            render_output = await self.scene_renderer.render(camera)
            render_time = (time.perf_counter() - render_start) * 1000

            # 2. Encode
            encode_start = time.perf_counter()
            payload = await self.encoder.encode(render_output, camera.frame_id)
            encode_time = (time.perf_counter() - encode_start) * 1000

            # 3. Send
            send_start = time.perf_counter()
            await self.send_payload(payload)
            send_time = (time.perf_counter() - send_start) * 1000

            total_time = (time.perf_counter() - total_start) * 1000

            # Metrics ê¸°ë¡
            self.metrics["render_times"].append(render_time)
            self.metrics["encode_times"].append(encode_time)
            self.metrics["send_times"].append(send_time)
            self.metrics["total_times"].append(total_time)

            # ì£¼ê¸°ì ìœ¼ë¡œ ì¶œë ¥ (100 í”„ë ˆì„ë§ˆë‹¤)
            if camera.frame_id % 100 == 0:
                self.print_metrics()

            camera_queue.task_done()

    def print_metrics(self):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¶œë ¥"""
        import numpy as np

        print(f"\nğŸ“Š Performance Metrics (last 100 frames):")
        print(f"  Render:  avg={np.mean(self.metrics['render_times'][-100:]):.2f}ms")
        print(f"  Encode:  avg={np.mean(self.metrics['encode_times'][-100:]):.2f}ms")
        print(f"  Send:    avg={np.mean(self.metrics['send_times'][-100:]):.2f}ms")
        print(f"  Total:   avg={np.mean(self.metrics['total_times'][-100:]):.2f}ms")
        print(f"  Target:  16.67ms (60 FPS)\n")
```

---

## ë””ë²„ê¹… ë° ëª¨ë‹ˆí„°ë§

### 1. ë¡œê¹… ì„¤ì •

```python
# renderer/main.py

import logging

def setup_logging(level=logging.INFO):
    """ë¡œê¹… ì„¤ì •"""
    logging.basicConfig(
        level=level,
        format='[%(asctime)s] %(levelname)s - %(name)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )

    # ê° ëª¨ë“ˆë³„ ë¡œê±°
    logging.getLogger('renderer.service').setLevel(logging.DEBUG)
    logging.getLogger('renderer.scene').setLevel(logging.INFO)
    logging.getLogger('renderer.encoder').setLevel(logging.INFO)

if __name__ == "__main__":
    setup_logging()
    # ...
```

### 2. Frame ID ì¶”ì 

```python
class RendererService:
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.last_received_frame_id = -1
        self.last_sent_frame_id = -1

    async def camera_receive_loop(self, camera_queue: asyncio.Queue):
        while True:
            packet = await self.camera_reader.read(152)
            camera = parse_camera_frame(packet)

            # Frame ID ì—°ì†ì„± ì²´í¬
            if camera.frame_id != self.last_received_frame_id + 1:
                print(f"âš ï¸  Frame skip detected: {self.last_received_frame_id} â†’ {camera.frame_id}")

            self.last_received_frame_id = camera.frame_id
            await camera_queue.put(camera)

    async def send_payload(self, payload: RenderPayload):
        # ...

        # Frame ID ì¶”ì 
        self.last_sent_frame_id = payload.frame_id
        print(f"ğŸ“¤ Sent frame {payload.frame_id}")
```

### 3. ì¤‘ê°„ ê²°ê³¼ ì €ì¥ (ë””ë²„ê¹…)

```python
class DebugJPEGEncoder(JPEGEncoder):
    """ë””ë²„ê¹…ìš© Encoder (ì¤‘ê°„ ê²°ê³¼ ì €ì¥)"""

    def __init__(self, *args, save_dir="/tmp/debug_frames", **kwargs):
        super().__init__(*args, **kwargs)
        self.save_dir = save_dir
        os.makedirs(save_dir, exist_ok=True)

    async def encode(self, output: RenderOutput, frame_id: int) -> RenderPayload:
        # ì •ìƒ ì¸ì½”ë”©
        payload = await super().encode(output, frame_id)

        # ì¤‘ê°„ ê²°ê³¼ ì €ì¥ (10 í”„ë ˆì„ë§ˆë‹¤)
        if frame_id % 10 == 0:
            # Color ì €ì¥
            color_uint8 = (output.color * 255).clamp(0, 255).to(torch.uint8).cpu().numpy()
            cv2.imwrite(f"{self.save_dir}/color_{frame_id:06d}.png",
                       cv2.cvtColor(color_uint8, cv2.COLOR_RGB2BGR))

            # Depth ì €ì¥ (visualization)
            depth_vis = (output.depth.cpu().numpy() * 255).astype(np.uint8)
            cv2.imwrite(f"{self.save_dir}/depth_{frame_id:06d}.png", depth_vis)

            print(f"ğŸ’¾ Saved debug frames: {frame_id}")

        return payload
```

### 4. Health Check

```python
class RendererService:
    async def health_check_loop(self, interval=10):
        """ì£¼ê¸°ì ì¸ í—¬ìŠ¤ ì²´í¬"""
        while True:
            await asyncio.sleep(interval)

            # GPU ë©”ëª¨ë¦¬ ì²´í¬
            allocated = torch.cuda.memory_allocated() / 1e9
            reserved = torch.cuda.memory_reserved() / 1e9

            # Queue ìƒíƒœ ì²´í¬
            queue_size = self.camera_queue.qsize()

            # Socket ì—°ê²° ìƒíƒœ
            camera_connected = self.camera_writer and not self.camera_writer.is_closing()
            video_connected = self.video_writer and not self.video_writer.is_closing()

            print(f"ğŸ’š Health Check:")
            print(f"  GPU: {allocated:.2f}GB / {reserved:.2f}GB")
            print(f"  Queue: {queue_size} / {self.camera_queue.maxsize}")
            print(f"  Sockets: camera={camera_connected}, video={video_connected}")

    async def run(self):
        await asyncio.gather(
            self.camera_receive_loop(self.camera_queue),
            self.render_and_send_loop(self.camera_queue),
            self.health_check_loop(interval=10)  # 10ì´ˆë§ˆë‹¤
        )
```

---

## ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 1 (MVP) ë°°í¬ ì „ í™•ì¸ì‚¬í•­

**ì½”ë“œ:**
- [ ] `renderer/data_types.py` êµ¬í˜„ ì™„ë£Œ
- [ ] `renderer/scene_renderers/base.py` êµ¬í˜„ ì™„ë£Œ
- [ ] `renderer/scene_renderers/gaussian_splatting.py` êµ¬í˜„ ì™„ë£Œ
- [ ] `renderer/encoders/base.py` êµ¬í˜„ ì™„ë£Œ
- [ ] `renderer/encoders/jpeg.py` êµ¬í˜„ ì™„ë£Œ
- [ ] `renderer/utils/protocol.py` êµ¬í˜„ ì™„ë£Œ
- [ ] `renderer/renderer_service.py` êµ¬í˜„ ì™„ë£Œ
- [ ] `renderer/main.py` ì§„ì…ì  êµ¬í˜„

**í…ŒìŠ¤íŠ¸:**
- [ ] í…ŒìŠ¤íŠ¸ 1: Unix Socket ìƒì„± (PASS)
- [ ] í…ŒìŠ¤íŠ¸ 2: Socket ì–‘ë°©í–¥ í†µì‹  (PASS)
- [ ] í…ŒìŠ¤íŠ¸ 3: Scene Renderer ë‹¨ë… (PASS)
- [ ] í…ŒìŠ¤íŠ¸ 4: Encoder ë‹¨ë… (PASS)
- [ ] í…ŒìŠ¤íŠ¸ 5: E2E ë°ì´í„° íŒ¨ìŠ¤ (PASS)

**ì„±ëŠ¥:**
- [ ] ë Œë”ë§ ë ˆì´í„´ì‹œ < 16.67ms (60 FPS)
- [ ] E2E ë ˆì´í„´ì‹œ < 50ms
- [ ] GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
- [ ] 100 í”„ë ˆì„ ì—°ì† ë Œë”ë§ ì•ˆì •ì„±

**Docker:**
- [ ] `renderer/Dockerfile` ì‘ì„±
- [ ] `renderer/requirements.txt` ì‘ì„±
- [ ] Docker ì´ë¯¸ì§€ ë¹Œë“œ ì„±ê³µ
- [ ] Docker Compose í†µí•© í…ŒìŠ¤íŠ¸

**ë¬¸ì„œ:**
- [ ] README.md ì—…ë°ì´íŠ¸
- [ ] API ë¬¸ì„œ ì‘ì„±
- [ ] ë°°í¬ ê°€ì´ë“œ ì‘ì„±

**í†µí•©:**
- [ ] Transport Serviceì™€ ì—°ê²° í™•ì¸
- [ ] Frontendì™€ E2E í…ŒìŠ¤íŠ¸
- [ ] Frame ID ì¼ì¹˜ í™•ì¸
- [ ] ë°ì´í„° ë¬´ê²°ì„± í™•ì¸

---

## ê²°ë¡ 

ì´ ì•„í‚¤í…ì²˜ëŠ” **ëª¨ë“ˆí™”**, **í™•ì¥ì„±**, **ì„±ëŠ¥**ì„ ëª¨ë‘ ê³ ë ¤í•œ ì„¤ê³„ì…ë‹ˆë‹¤.

**í•µì‹¬ ì›ì¹™:**
- âœ… ê´€ì‹¬ì‚¬ì˜ ë¶„ë¦¬
- âœ… ì¡°í•© ê°€ëŠ¥ì„±
- âœ… í™•ì¥ ê°€ëŠ¥ì„±
- âœ… YAGNI (í•„ìš”ì‹œ í™•ì¥)

**ë‹¤ìŒ ë‹¨ê³„:**
1. Phase 1 êµ¬í˜„ (MVP)
2. í†µí•© í…ŒìŠ¤íŠ¸
3. ì„±ëŠ¥ ì¸¡ì •
4. Phase 2 í™•ì¥ ê¸°ëŠ¥ ì¶”ê°€
