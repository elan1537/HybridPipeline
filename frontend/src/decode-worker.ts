// Import debug logger for worker
interface DebugLogger {
    setDebugEnabled(enabled: boolean): void;
    isDebugEnabled(): boolean;
    logWorker(message: string, ...args: any[]): void;
    warn(message: string, ...args: any[]): void;
    error(message: string, ...args: any[]): void;
}

// Simple debug logger implementation for worker
const debug: DebugLogger = {
    debugEnabled: false,

    setDebugEnabled(enabled: boolean): void {
        this.debugEnabled = enabled;
        if (enabled) {
            console.log('ğŸ› Worker debug logging enabled');
        }
    },

    isDebugEnabled(): boolean {
        return this.debugEnabled;
    },

    logWorker(message: string, ...args: any[]): void {
        if (this.debugEnabled) {
            console.log(`[DEBUG WORKER] ${message}`, ...args);
        }
    },

    warn(message: string, ...args: any[]): void {
        if (this.debugEnabled) {
            console.warn(`[DEBUG WORKER WARN] ${message}`, ...args);
        }
    },

    error(message: string, ...args: any[]): void {
        if (this.debugEnabled) {
            console.error(`[DEBUG WORKER ERROR] ${message}`, ...args);
        }
    }
};

let videoDecoder: VideoDecoder
let ws: WebSocket
let decoderInitialized = false;
let cachedDescription: Uint8Array | undefined = undefined;  // SPS/PPS cache for reconnection

let rtWidth = 1920
let rtHeight = 1080

let rgbaTemp: Uint8Array

let decodeCnt = 0
let renderCnt = 0
let decodeStart = performance.now()
let renderStart = performance.now()
let jpegFallback = false

// ìˆœìˆ˜ ë””ì½”ë”© ì„±ëŠ¥ ì¸¡ì •ì„ ìœ„í•œ ë³€ìˆ˜ë“¤
let pureDecodeCount = 0
let pureDecodeStart = performance.now()
let frameDecodeStartTime = 0
let totalDecodeTime = 0
let minDecodeTime = Infinity
let maxDecodeTime = 0

// FPS ì¸¡ì • ì¤‘ ìƒ˜í”Œë§ ë°ì´í„° (60ì´ˆ ì¸¡ì •ìš©)
let fpsMeasurementSamples: number[] = []
let lastSampleTime = 0
let fpsMeasurementActive = false

// ì„±ëŠ¥ ì¸¡ì • íˆìŠ¤í† ë¦¬ (ìµœê·¼ 100ê°œ í”„ë ˆì„)
const decodeTimeHistory: number[] = []
const maxHistorySize = 100

// H264 ë””ì½”ë”©ìš© pending frames ì¶”ì 
const pendingFrames = new Map<number, {
    frameId: number,
    serverTimestamps: {
        serverReceiveTime: number,
        serverProcessStartTime: number,
        serverProcessEndTime: number,
        serverSendTime: number
    }
}>()


interface InitMessage {
    type: 'init'
    canvas: OffscreenCanvas
    width: number
    height: number
    wsURL: string
}

interface ChunkMessage {
    type: 'chunk'
    data: ArrayBuffer
}

interface CameraMessage {
    type: 'camera'
    position: Float32Array
    target: Float32Array
    intrinsics: Float32Array
    projection: Float32Array
    frameId?: number,
    timeIndex: number,
}

interface ConnectionMessage {
    type: 'change'
    wsURL: string
}

interface CloseMessage {
    type: 'ws-close',
}

interface PingMessage {
    type: 'ping'
    clientTime: number
}

interface LatencyMessage {
    type: 'latency-update'
    frameId: number
    serverTimestamps?: {
        serverReceiveTime: number
        serverProcessStartTime: number
        serverProcessEndTime: number
        serverSendTime: number
    }
}

interface FPSMeasurementStartMessage {
    type: 'fps-measurement-start'
}

interface FPSMeasurementStopMessage {
    type: 'fps-measurement-stop'
}

interface DebugToggleMessage {
    type: 'debug-toggle'
    enabled: boolean
}

self.onmessage = async (evt: MessageEvent<InitMessage | ChunkMessage | CameraMessage | ConnectionMessage | CloseMessage | PingMessage | LatencyMessage | FPSMeasurementStartMessage | FPSMeasurementStopMessage | DebugToggleMessage>) => {
    const data = evt.data

    switch (data.type) {
        case 'init':
            debug.logWorker('Received message:', data)
            await init(data)
            break
        case 'chunk':
            decodeChunk(data.data)
            break
        case 'camera':
            updateCamera(data)
            break
        case 'change':
            ws.close(1000, "Connection changed")
            jpegFallback = !jpegFallback
            await initWebSocket(data.wsURL)
            break
        case 'ws-close':
            ws.close(1000, "Connection closed")
            self.postMessage({ type: 'ws-close' })
            break
        case 'ping':
            sendPing(data.clientTime)
            break
        case 'latency-update':
            // Main threadì—ì„œ latency trackerë¡œ ì „ë‹¬
            self.postMessage({
                type: 'latency-update',
                frameId: data.frameId,
                serverTimestamps: data.serverTimestamps
            })
            break
        case 'fps-measurement-start':
            // FPS ì¸¡ì • ì‹œì‘
            fpsMeasurementActive = true
            fpsMeasurementSamples = []
            lastSampleTime = performance.now()
            debug.logWorker('FPS measurement started')
            break
        case 'fps-measurement-stop':
            // FPS ì¸¡ì • ì¤‘ì§€
            fpsMeasurementActive = false
            debug.logWorker('FPS measurement stopped')
            break
        case 'debug-toggle':
            // Debug logging í† ê¸€
            debug.setDebugEnabled(data.enabled)
            break
    }
}

function parseH264Message(data: ArrayBuffer) {
    const dv = new DataView(data)
    const HEADER_SIZE = 4 + 4 + 8 + 8 + 8 + 8; // videoLen + frameId + 4 timestamps
    if (data.byteLength < HEADER_SIZE) return null;

    const videoLen = dv.getUint32(0, true);
    const frameId = dv.getUint32(4, true);
    const clientSendTime = dv.getFloat64(8, true);
    const serverReceiveTime = dv.getFloat64(16, true);
    const serverProcessEndTime = dv.getFloat64(24, true);
    const serverSendTime = dv.getFloat64(32, true);
    const videoStart = HEADER_SIZE;

    if (data.byteLength < videoStart + videoLen) return null;

    return {
        frameId,
        videoData: data.slice(videoStart, videoStart + videoLen),
        serverTimestamps: {
            serverReceiveTime,
            serverProcessStartTime: serverReceiveTime, // ì²˜ë¦¬ ì‹œì‘ì€ ìˆ˜ì‹ ê³¼ ê°™ë‹¤ê³  ê°€ì •
            serverProcessEndTime,
            serverSendTime
        }
    }
}

function parseJPEGMessage(data: ArrayBuffer): {
    frameId: number,
    jpegData: ArrayBuffer,
    depthData: ArrayBuffer,
    serverTimestamps: {
        serverReceiveTime: number,
        serverProcessStartTime: number,
        serverProcessEndTime: number,
        serverSendTime: number
    }
} | null {
    const dv = new DataView(data)
    const HEADER_SIZE = 4 + 4 + 4 + 8 + 8 + 8 + 8; // jpeg_len + depth_len + frameId + 4 timestamps

    if (data.byteLength < HEADER_SIZE) {
        debug.error(`JPEG message too short: ${data.byteLength} < ${HEADER_SIZE}`)
        return null;
    }

    const jpegLen = dv.getUint32(0, true)
    const depthLen = dv.getUint32(4, true)
    const frameId = dv.getUint32(8, true)
    const clientSendTime = dv.getFloat64(12, true)
    const serverReceiveTime = dv.getFloat64(20, true)
    const serverProcessEndTime = dv.getFloat64(28, true)
    const serverSendTime = dv.getFloat64(36, true)
    const jpegStart = HEADER_SIZE

    if (data.byteLength < jpegStart + jpegLen + depthLen) {
        debug.error(`JPEG message incomplete: expected ${jpegStart + jpegLen + depthLen}, got ${data.byteLength}`)
        return null;
    }

    return {
        frameId,
        jpegData: data.slice(jpegStart, jpegStart + jpegLen),
        depthData: data.slice(jpegStart + jpegLen, jpegStart + jpegLen + depthLen),
        serverTimestamps: {
            serverReceiveTime,
            serverProcessStartTime: serverReceiveTime,
            serverProcessEndTime,
            serverSendTime
        }
    }
}

function updateCamera(data: CameraMessage) {
    const position = new Float32Array(data.position);
    const target = new Float32Array(data.target);
    const intrinsics = new Float32Array(data.intrinsics);
    const projection = new Float32Array(data.projection);

    // Debug: timeIndex ê°’ í™•ì¸
    debug.logWorker(`[updateCamera] Received timeIndex: ${data.timeIndex} (type: ${typeof data.timeIndex})`);

    const dv = new Float32Array(32); // 32 * 4 = 128 bytes

    // position (3 floats)
    dv.set(position, 0);

    // target (3 floats) 
    dv.set(target, 3);

    // intrinsics (9 floats)
    dv.set(intrinsics, 6);

    // padding (1 float) - ì„œë²„ì—ì„œ ê¸°ëŒ€í•˜ëŠ” 0.0 ê°’
    dv[15] = 0.0;

    // projection (16 floats)
    dv.set(projection, 16);

    // frameIdì™€ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€ (4 + 4(íŒ¨ë”©) + 8 = 16 bytes)
    const timestamp = performance.timeOrigin + performance.now();
    const frameId = data.frameId || 0;

    // ìµœì¢… ë²„í¼ ìƒì„± (128 + 16 = 144 bytes, 8ë°”ì´íŠ¸ ì •ë ¬ì„ ìœ„í•´ íŒ¨ë”© ì¶”ê°€)
    const finalBuffer = new ArrayBuffer(160);
    const floatView = new Float32Array(finalBuffer, 0, 32);
    const frameIdView = new Uint32Array(finalBuffer, 128, 1);
    // 132ëŠ” 8ì˜ ë°°ìˆ˜ê°€ ì•„ë‹ˆë¯€ë¡œ 136ìœ¼ë¡œ ì¡°ì • (8ë°”ì´íŠ¸ ì •ë ¬)
    const timestampView = new Float64Array(finalBuffer, 136, 1);
    const timeIndexView = new Float32Array(finalBuffer, 144, 1);


    floatView.set(dv);
    frameIdView[0] = frameId;
    timestampView[0] = timestamp;
    timeIndexView[0] = (typeof data.timeIndex === 'number' && !isNaN(data.timeIndex)) ? data.timeIndex : 0.0;

    ws.send(finalBuffer);
}

function sendPing(clientTime: number) {
    if (!ws || ws.readyState !== WebSocket.OPEN) return;

    // Ping ë©”ì‹œì§€: type(1 byte) + padding(7 bytes) + clientTime(8 bytes) = 16 bytes (8ë°”ì´íŠ¸ ì •ë ¬)
    const buffer = new ArrayBuffer(16);
    const typeView = new Uint8Array(buffer, 0, 1);
    const timeView = new Float64Array(buffer, 8, 1);  // 8ë°”ì´íŠ¸ ì •ë ¬ëœ ìœ„ì¹˜

    typeView[0] = 255; // ping message type
    timeView[0] = clientTime;

    ws.send(buffer);
}

// ìˆœìˆ˜ ë””ì½”ë”© ì„±ëŠ¥ ì¸¡ì • í•¨ìˆ˜ë“¤
function recordDecodeStart() {
    frameDecodeStartTime = performance.now();
}

function recordDecodeComplete() {
    if (frameDecodeStartTime === 0) return;

    const decodeTime = performance.now() - frameDecodeStartTime;
    pureDecodeCount++;
    totalDecodeTime += decodeTime;
    minDecodeTime = Math.min(minDecodeTime, decodeTime);
    maxDecodeTime = Math.max(maxDecodeTime, decodeTime);

    // FPS ì¸¡ì • ì¤‘ì´ë©´ 1ì´ˆë§ˆë‹¤ ìƒ˜í”Œ ìˆ˜ì§‘
    if (fpsMeasurementActive) {
        const now = performance.now();
        if (now - lastSampleTime >= 1000) {
            // 1ì´ˆê°„ì˜ ìˆœìˆ˜ ë””ì½”ë”© FPS ê³„ì‚°
            const duration = (now - lastSampleTime) / 1000;
            const sampleFPS = pureDecodeCount / duration;

            // FPS ê°’ ê²€ì¦ ë° ìƒ˜í”Œ ì¶”ê°€
            if (sampleFPS > 0 && sampleFPS <= 240 && isFinite(sampleFPS)) {
                fpsMeasurementSamples.push(sampleFPS);
                debug.logWorker(`Decode FPS sample: ${sampleFPS.toFixed(2)} fps`);
            } else {
                debug.warn(`Invalid decode FPS sample: ${sampleFPS.toFixed(2)} fps`);
            }

            lastSampleTime = now;
            // pureDecodeCountëŠ” ë¦¬ì…‹í•˜ì§€ ì•ŠìŒ (ì „ì²´ í†µê³„ì— ì‚¬ìš©)
        }
    }

    // íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
    decodeTimeHistory.push(decodeTime);
    if (decodeTimeHistory.length > maxHistorySize) {
        decodeTimeHistory.shift();
    }

    frameDecodeStartTime = 0;

    // 1ì´ˆë§ˆë‹¤ ìˆœìˆ˜ ë””ì½”ë”© ì„±ëŠ¥ í†µê³„ ì „ì†¡
    const now = performance.now();
    if (now - pureDecodeStart > 1000) {
        const duration = (now - pureDecodeStart) / 1000;
        const pureFPS = pureDecodeCount / duration;
        const avgDecodeTime = totalDecodeTime / pureDecodeCount;

        // ìµœê·¼ í”„ë ˆì„ë“¤ì˜ ë””ì½”ë”© ì‹œê°„ ë¶„ì„
        const recentTimes = decodeTimeHistory.slice(-Math.min(60, decodeTimeHistory.length));
        const recentAvg = recentTimes.reduce((a, b) => a + b, 0) / recentTimes.length;
        const recentMin = Math.min(...recentTimes);
        const recentMax = Math.max(...recentTimes);

        self.postMessage({
            type: 'pure-decode-stats',
            pureFPS,
            avgDecodeTime,
            minDecodeTime: minDecodeTime === Infinity ? 0 : minDecodeTime,
            maxDecodeTime,
            recentAvg,
            recentMin,
            recentMax,
            totalFrames: pureDecodeCount,
            // FPS ì¸¡ì • ì¤‘ì´ë©´ ìƒ˜í”Œ ë°ì´í„° ì „ì†¡
            fpsMeasurementData: fpsMeasurementActive && fpsMeasurementSamples.length > 0 ? {
                totalCount: fpsMeasurementSamples.length,
                avgTime: fpsMeasurementSamples.reduce((a, b) => a + b, 0) / fpsMeasurementSamples.length > 0 ?
                    1000 / (fpsMeasurementSamples.reduce((a, b) => a + b, 0) / fpsMeasurementSamples.length) : 0
            } : null
        });

        debug.logWorker(`Pure decode stats: ${pureFPS.toFixed(2)} fps, FPS measurement ${fpsMeasurementActive ? 'ACTIVE' : 'inactive'} (${fpsMeasurementSamples.length} samples)`);

        // 1ì´ˆ ë‹¨ìœ„ ì¹´ìš´í„°ë§Œ ë¦¬ì…‹ (FPS ì¸¡ì • ëˆ„ì  ë°ì´í„°ëŠ” ìœ ì§€)
        pureDecodeCount = 0;
        pureDecodeStart = now;
        totalDecodeTime = 0;
        minDecodeTime = Infinity;
        maxDecodeTime = 0;
    }
}

async function initDecoder() {
    if (decoderInitialized) return;

    debug.logWorker("initDecoder")

    // Safari í˜¸í™˜ì„± ì²´í¬
    if (typeof VideoDecoder === 'undefined') {
        debug.error('VideoDecoder API not supported in this browser');
        return;
    }

    try {
        videoDecoder = new VideoDecoder({
            output: handleFrame,
            error: e => {
                debug.error('Decoder error', e)
                debug.error('Decoder state:', videoDecoder?.state)
                debug.error('Decoder config:', {
                    codec: 'avc1.42E01E',
                    codedWidth: rtWidth,
                    codedHeight: rtHeight * 2
                })
                decoderInitialized = false;
                // ì—ëŸ¬ ë°œìƒ ì‹œ ë””ì½”ë”ë¥¼ ë‹«ê³  ì¬ì‹œë„ ì¤€ë¹„
                if (videoDecoder && videoDecoder.state !== 'closed') {
                    videoDecoder.close();
                }
            }
        });

        const config: VideoDecoderConfig = {
            codec: 'avc1.42E01E',
            codedWidth: rtWidth,
            codedHeight: rtHeight * 2,
        };

        const { supported } = await VideoDecoder.isConfigSupported(config);
        if (!supported) {
            debug.error('VideoDecoder config unsupported');
            return;
        }

        videoDecoder.configure(config);
        decoderInitialized = true;
        debug.logWorker("Decoder initialized successfully");

    } catch (error) {
        debug.error('Failed to initialize decoder:', error);
        decoderInitialized = false;
    }
}

async function initWebSocket(wsURL: string) {
    debug.logWorker("initWebSocket")
    debug.logWorker("URL: ", wsURL)
    ws = new WebSocket(wsURL);
    debug.logWorker("WS: ", ws)
    ws.binaryType = 'arraybuffer';
    ws.onopen = () => {
        debug.logWorker('[MediaWorker] WS opened')
        self.postMessage({ type: 'ws-ready' })
        const buf = new ArrayBuffer(4);
        new DataView(buf).setUint16(0, rtWidth, true);
        new DataView(buf).setUint16(2, rtHeight, true);
        ws.send(buf);
    }
    ws.onmessage = async e => {
        const arrBuf = e.data as ArrayBuffer;
        const clientReceiveTime = performance.now();

        // Ping response ì²˜ë¦¬ (type(1) + padding(7) + clientTime(8) + serverTime(8) = 24 bytes)
        if (arrBuf.byteLength === 24) {
            const dv = new DataView(arrBuf);
            const type = dv.getUint8(0);
            if (type === 254) { // pong message type
                const clientTime = dv.getFloat64(8, true);   // 8ë°”ì´íŠ¸ ì •ë ¬ëœ ìœ„ì¹˜
                const serverTime = dv.getFloat64(16, true);  // 16ë°”ì´íŠ¸ ìœ„ì¹˜

                self.postMessage({
                    type: 'pong-received',
                    clientRequestTime: clientTime,
                    serverReceiveTime: serverTime,
                    serverSendTime: serverTime, // ê°„ë‹¨íˆ ë™ì¼í•˜ë‹¤ê³  ê°€ì •
                    clientResponseTime: clientReceiveTime
                });
                return;
            }
        }

        if (jpegFallback) {
            const parseResult = parseJPEGMessage(arrBuf);
            if (!parseResult) {
                debug.error("Failed to parse JPEG message");
                return;
            }

            const { frameId, jpegData, depthData, serverTimestamps } = parseResult;

            // ìˆœìˆ˜ ë””ì½”ë”© ì‹œì‘ ì‹œì  ê¸°ë¡
            recordDecodeStart();
            const colorBitmap = await createImageBitmap(new Blob([jpegData], { type: 'image/jpeg' }));
            // JPEG ë””ì½”ë”© ì™„ë£Œ ì‹œì  ê¸°ë¡ (createImageBitmap ì™„ë£Œ í›„)
            recordDecodeComplete();

            const depthFloat16 = new Uint16Array(depthData);

            // ë ˆì´í„´ì‹œ ì¶”ì  ì •ë³´ ì „ë‹¬
            self.postMessage({
                type: 'frame-receive',
                frameId,
                serverTimestamps,
                clientReceiveTime
            });

            decodeCnt++;
            const decodeCompleteTime = performance.now();

            self.postMessage({
                type: 'frame',
                frameId,
                image: colorBitmap,
                depth: depthFloat16,
                decodeCompleteTime
            });

            const now = performance.now();
            if (now - decodeStart > 1000) {
                const fps = decodeCnt / ((now - decodeStart) / 1000);
                self.postMessage({ type: 'fps', decode: fps });
                decodeCnt = 0;
                decodeStart = now;
            }
        } else {
            const parseResult = parseH264Message(arrBuf);
            if (!parseResult) {
                debug.error("Failed to parse H264 message");
                return;
            }

            const { frameId, videoData, serverTimestamps } = parseResult;

            // ë ˆì´í„´ì‹œ ì¶”ì  ì •ë³´ ì „ë‹¬
            self.postMessage({
                type: 'frame-receive',
                frameId,
                serverTimestamps,
                clientReceiveTime
            });

            if (!decoderInitialized) {
                await initDecoder();
            }

            const chunk = new EncodedVideoChunk({
                type: 'key',
                timestamp: performance.now(),
                data: videoData
            });

            // frameIdë¥¼ VideoFrameì— ì—°ê²°í•˜ê¸° ìœ„í•´ ì €ì¥
            pendingFrames.set(chunk.timestamp, {
                frameId,
                serverTimestamps
            });

            // H264 ìˆœìˆ˜ ë””ì½”ë”© ì‹œì‘ ì‹œì  ê¸°ë¡ (VideoDecoder.decode í˜¸ì¶œ ì§ì „)
            recordDecodeStart();
            videoDecoder.decode(chunk);
        }
    };
    ws.onerror = e => {
        debug.error('WS error', e)
        self.postMessage({ type: 'ws-error' })
    }
    ws.onclose = e => {
        debug.logWorker('WS closed', e.code)
        self.postMessage({ type: 'ws-close' })
    }
}

async function init({ width, height, wsURL }: InitMessage) {
    rtWidth = width
    rtHeight = height

    rgbaTemp = new Uint8Array(rtWidth * rtHeight * 4)

    await initWebSocket(wsURL)

}

async function splitFrameCanvas(frame: VideoFrame, w: number, h: number) {
    const full = await createImageBitmap(frame);   // 1280Ã—1440
    const [cCan, dCan] = [new OffscreenCanvas(w, h), new OffscreenCanvas(w, h)];

    cCan.getContext('2d')!.drawImage(full, 0, 0, w, h, 0, 0, w, h);
    dCan.getContext('2d')!.drawImage(full, 0, h, w, h, 0, 0, w, h);

    return Promise.all([createImageBitmap(cCan), createImageBitmap(dCan)]);
}

async function handleFrame(frame: VideoFrame) {
    // H264 ìˆœìˆ˜ ë””ì½”ë”© ì™„ë£Œ ì‹œì  ê¸°ë¡ (VideoDecoderì˜ output ì½œë°±ì´ë¯€ë¡œ ì‹¤ì œ í•˜ë“œì›¨ì–´ ë””ì½”ë”© ì™„ë£Œ)
    recordDecodeComplete();

    decodeCnt++;
    const decodeCompleteTime = performance.now();

    const w = frame.codedWidth
    const h = frame.codedHeight / 2;

    const [colorBitmap, depthBitmap] = await splitFrameCanvas(frame, w, h);

    // pending frame ì •ë³´ ì°¾ê¸°
    const frameInfo = pendingFrames.get(frame.timestamp);
    let frameId = 0;

    if (frameInfo) {
        frameId = frameInfo.frameId;
        pendingFrames.delete(frame.timestamp);
    }

    frame.close();

    self.postMessage({
        type: 'frame',
        frameId,
        image: colorBitmap,
        depth: depthBitmap,
        decodeCompleteTime
    });

    const now = performance.now();

    if (now - decodeStart > 1000) {
        const fps = decodeCnt / ((now - decodeStart) / 1000);
        self.postMessage({ type: 'fps', decode: fps });
        decodeCnt = 0;
        decodeStart = now;
    }
}

function decodeChunk(arrayBuf: ArrayBuffer) {
    if (!decoderInitialized) {
        debug.warn('Decoder not initialized, skipping chunk');
        return;
    }

    const chunk = new EncodedVideoChunk({
        type: 'key',
        timestamp: performance.now(),
        data: arrayBuf,
    })

    videoDecoder.decode(chunk)
}
