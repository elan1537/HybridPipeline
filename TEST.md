# HybridPipeline Test Plan

## ê°œìš”

HybridPipelineì˜ í•µì‹¬ ê¸°ëŠ¥ ê²€ì¦ì„ ìœ„í•œ í…ŒìŠ¤íŠ¸ ê³„íšì…ë‹ˆë‹¤.

**í…ŒìŠ¤íŠ¸ ì² í•™:**
- âœ… **MVP ë¨¼ì €**: ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ ë™ì‘ í™•ì¸
- âœ… **ì‹¤ìš©ì **: ì‹¤ì œ ë°œìƒ ê°€ëŠ¥í•œ ë¬¸ì œì— ì§‘ì¤‘
- âœ… **ì ì§„ì **: í•„ìˆ˜ â†’ ì•ˆì •ì„± â†’ ìµœì í™” ìˆœì„œ

**ìš°ì„ ìˆœìœ„:**
1. **Phase 1 (MVP í•„ìˆ˜)**: ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ ë™ì‘
2. **Phase 2 (ì•ˆì •ì„±)**: ìš´ì˜ í™˜ê²½ ì¤€ë¹„
3. **Phase 3 (ì¶”ê°€)**: ì—£ì§€ ì¼€ì´ìŠ¤ ëŒ€ì‘
4. **Phase 4 (í›„ìˆœìœ„)**: ìš´ì˜ ì¤‘ í•„ìš”ì‹œ ì¶”ê°€

---

## í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì •

### í•„ìˆ˜ ë„êµ¬

```bash
# Python í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬
pip install pytest pytest-asyncio pytest-timeout

# ì¶”ê°€ ë„êµ¬
pip install pytest-cov  # ì»¤ë²„ë¦¬ì§€ ì¸¡ì •
```

### í…ŒìŠ¤íŠ¸ ë°ì´í„°

```
test/
â”œâ”€â”€ fixtures/
â”‚   â”œâ”€â”€ scenes/
â”‚   â”‚   â”œâ”€â”€ minimal_scene.ply       # ìµœì†Œ Scene (10 gaussians)
â”‚   â”‚   â””â”€â”€ test_scene.ply          # í…ŒìŠ¤íŠ¸ Scene
â”‚   â””â”€â”€ expected/
â”‚       â”œâ”€â”€ camera_frame_001.bin    # 152 bytes
â”‚       â””â”€â”€ render_output_001.pkl
â””â”€â”€ sockets/
    â””â”€â”€ test_*.sock                  # í…ŒìŠ¤íŠ¸ìš© Unix Socket
```

---

## Phase 1: MVP í•„ìˆ˜ í…ŒìŠ¤íŠ¸

> **ëª©í‘œ**: ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ì´ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸
> **ì‹œê°„**: 2-3ì¼
> **í…ŒìŠ¤íŠ¸ ê°œìˆ˜**: 5ê°œ

### 1. Unix Socket ìƒì„± í…ŒìŠ¤íŠ¸

**ëª©ì **: Socket íŒŒì¼ì´ ì •ìƒì ìœ¼ë¡œ ìƒì„±ë˜ëŠ”ì§€ í™•ì¸

```python
# transport/tests/test_socket_creation.py

import os
import asyncio
import pytest

@pytest.mark.asyncio
async def test_unix_socket_creation():
    """Unix Socket ìƒì„± í…ŒìŠ¤íŠ¸"""
    camera_socket = "/tmp/test_camera.sock"
    video_socket = "/tmp/test_video.sock"

    # ê¸°ì¡´ ì†Œì¼“ ì œê±°
    for sock in [camera_socket, video_socket]:
        if os.path.exists(sock):
            os.remove(sock)

    # Transport ì„œë²„ ì‹œì‘
    async def dummy_handler(reader, writer):
        pass

    camera_server = await asyncio.start_unix_server(
        dummy_handler, camera_socket
    )
    video_server = await asyncio.start_unix_server(
        dummy_handler, video_socket
    )

    # ì†Œì¼“ íŒŒì¼ ìƒì„± í™•ì¸
    assert os.path.exists(camera_socket), "Camera socket not created"
    assert os.path.exists(video_socket), "Video socket not created"

    # ì†Œì¼“ íƒ€ì… í™•ì¸
    import stat
    assert stat.S_ISSOCK(os.stat(camera_socket).st_mode), "Not a socket file"
    assert stat.S_ISSOCK(os.stat(video_socket).st_mode), "Not a socket file"

    # ì •ë¦¬
    camera_server.close()
    video_server.close()
    await camera_server.wait_closed()
    await video_server.wait_closed()

    print("âœ… Unix Socket ìƒì„± ì„±ê³µ")
```

**ê²€ì¦ í•­ëª©:**
- [x] `/run/ipc/camera.sock` íŒŒì¼ ì¡´ì¬
- [x] `/run/ipc/video.sock` íŒŒì¼ ì¡´ì¬
- [x] Socket íŒŒì¼ íƒ€ì… í™•ì¸

---

### 2. Socket ì—°ê²° í…ŒìŠ¤íŠ¸ (ì–‘ë°©í–¥ í†µì‹ )

**ëª©ì **: Transportì™€ Rendererê°€ Unix Socketìœ¼ë¡œ ì—°ê²°ë˜ê³  ë°ì´í„°ë¥¼ ì£¼ê³ ë°›ì„ ìˆ˜ ìˆëŠ”ì§€ í™•ì¸

```python
# tests/test_socket_connection.py

import asyncio
import struct
import pytest

@pytest.mark.asyncio
async def test_transport_renderer_socket_connection():
    """Transport â†” Renderer ì–‘ë°©í–¥ í†µì‹  í…ŒìŠ¤íŠ¸"""
    camera_socket = "/tmp/test_camera.sock"
    video_socket = "/tmp/test_video.sock"

    # Transport: ì„œë²„ ì—­í• 
    camera_received = []
    video_sent = []

    async def camera_handler(reader, writer):
        """Camera ë°ì´í„° ìˆ˜ì‹ """
        data = await reader.read(152)
        camera_received.append(data)
        writer.close()
        await writer.wait_closed()

    async def video_handler(reader, writer):
        """Video ë°ì´í„° ì†¡ì‹ """
        # í…ŒìŠ¤íŠ¸ payload ì „ì†¡
        test_payload = b"x" * 100
        header = struct.pack("<QII", 1, 0, len(test_payload))  # frame_id=1
        writer.write(header + test_payload)
        await writer.drain()
        video_sent.append(test_payload)
        writer.close()
        await writer.wait_closed()

    camera_server = await asyncio.start_unix_server(
        camera_handler, camera_socket
    )
    video_server = await asyncio.start_unix_server(
        video_handler, video_socket
    )

    await asyncio.sleep(0.1)

    # Renderer: í´ë¼ì´ì–¸íŠ¸ ì—­í• 
    async def renderer_client():
        # Camera socket ì—°ê²° ë° ì „ì†¡
        camera_reader, camera_writer = await asyncio.open_unix_connection(
            camera_socket
        )
        test_camera_data = b"c" * 152  # 152 bytes
        camera_writer.write(test_camera_data)
        await camera_writer.drain()
        camera_writer.close()
        await camera_writer.wait_closed()

        # Video socket ì—°ê²° ë° ìˆ˜ì‹ 
        video_reader, video_writer = await asyncio.open_unix_connection(
            video_socket
        )
        header = await video_reader.read(16)
        frame_id, meta_len, data_len = struct.unpack("<QII", header)
        data = await video_reader.read(data_len)

        return frame_id, data

    frame_id, received_data = await renderer_client()

    # ê²€ì¦
    assert len(camera_received) == 1, "Camera data not received"
    assert camera_received[0] == b"c" * 152, "Camera data mismatch"

    assert frame_id == 1, "Frame ID mismatch"
    assert received_data == b"x" * 100, "Video data mismatch"

    # ì •ë¦¬
    camera_server.close()
    video_server.close()
    await camera_server.wait_closed()
    await video_server.wait_closed()

    print("âœ… Socket ì–‘ë°©í–¥ í†µì‹  ì„±ê³µ")
```

**ê²€ì¦ í•­ëª©:**
- [x] Transport â†’ Renderer: Camera ë°ì´í„° ì „ì†¡
- [x] Renderer â†’ Transport: Video ë°ì´í„° ìˆ˜ì‹ 
- [x] ë°ì´í„° ë¬´ê²°ì„± (ì†¡ì‹  == ìˆ˜ì‹ )

---

### 3. Scene Renderer ë™ì‘ í…ŒìŠ¤íŠ¸

**ëª©ì **: ê°œë³„ Rendererê°€ Camera ë°ì´í„°ë¥¼ ë°›ì•„ Sceneì„ ë Œë”ë§í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸

```python
# renderer/tests/test_scene_renderer.py

import pytest
import torch
import numpy as np
from scene_renderers.gaussian_splatting import GaussianSplattingRenderer
from data_types import CameraFrame, RenderOutput

@pytest.mark.asyncio
async def test_scene_renderer_render():
    """Scene Renderer ë Œë”ë§ í…ŒìŠ¤íŠ¸"""
    # Renderer ì´ˆê¸°í™”
    renderer = GaussianSplattingRenderer(
        ply_path="test/fixtures/scenes/minimal_scene.ply"
    )

    success = await renderer.on_init()
    assert success, "Renderer ì´ˆê¸°í™” ì‹¤íŒ¨"

    # í…ŒìŠ¤íŠ¸ Camera ìƒì„±
    camera = CameraFrame(
        view_matrix=np.eye(4, dtype=np.float32),
        intrinsics=create_test_intrinsics(width=640, height=480),
        time_index=0.0,
        frame_id=1,
        client_timestamp=0.0,
        server_timestamp=0.0
    )

    # ë Œë”ë§
    output = await renderer.render(camera)

    # ê²€ì¦: RenderOutput êµ¬ì¡°
    assert isinstance(output, RenderOutput), "Invalid output type"
    assert isinstance(output.color, torch.Tensor), "Color must be tensor"
    assert isinstance(output.depth, torch.Tensor), "Depth must be tensor"
    assert isinstance(output.alpha, torch.Tensor), "Alpha must be tensor"

    # ê²€ì¦: Shape
    assert output.color.shape == (480, 640, 3), f"Color shape mismatch: {output.color.shape}"
    assert output.depth.shape == (480, 640), f"Depth shape mismatch: {output.depth.shape}"
    assert output.alpha.shape == (480, 640), f"Alpha shape mismatch: {output.alpha.shape}"

    # ê²€ì¦: dtype
    assert output.color.dtype == torch.float32, "Color must be float32"
    assert output.depth.dtype == torch.float32, "Depth must be float32"
    assert output.alpha.dtype == torch.float32, "Alpha must be float32"

    # ê²€ì¦: ê°’ ë²”ìœ„
    assert torch.all(output.color >= 0) and torch.all(output.color <= 1), \
        "Color values must be in [0, 1]"
    assert torch.all(output.alpha >= 0) and torch.all(output.alpha <= 1), \
        "Alpha values must be in [0, 1]"

    # ì •ë¦¬
    await renderer.on_shutdown()

    print("âœ… Scene Renderer ë Œë”ë§ ì„±ê³µ")
    print(f"   Color: {output.color.shape}, range: [{output.color.min():.3f}, {output.color.max():.3f}]")
    print(f"   Depth: {output.depth.shape}, range: [{output.depth.min():.3f}, {output.depth.max():.3f}]")
    print(f"   Alpha: {output.alpha.shape}, range: [{output.alpha.min():.3f}, {output.alpha.max():.3f}]")


def create_test_intrinsics(width, height, fov=60):
    """í…ŒìŠ¤íŠ¸ìš© Intrinsics ìƒì„±"""
    focal_length = width / (2 * np.tan(np.radians(fov) / 2))
    intrinsics = np.array([
        [focal_length, 0, width / 2, 0],
        [0, focal_length, height / 2, 0],
        [0, 0, 1, 0],
        [0, 0, 0, 1]
    ], dtype=np.float32)
    return intrinsics
```

**ê²€ì¦ í•­ëª©:**
- [x] Renderer ì´ˆê¸°í™” ì„±ê³µ
- [x] RenderOutput ìƒì„±
- [x] Color: (H, W, 3), float32, [0, 1]
- [x] Depth: (H, W), float32
- [x] Alpha: (H, W), float32, [0, 1]

---

### 4. Encoder ë™ì‘ í…ŒìŠ¤íŠ¸ â­

**ëª©ì **: RenderOutputì´ ì˜¬ë°”ë¥´ê²Œ ì¸ì½”ë”©ë˜ëŠ”ì§€ í™•ì¸

```python
# renderer/tests/test_encoder.py

import pytest
import torch
from encoders.jpeg import JPEGEncoder
from data_types import RenderOutput, RenderPayload

@pytest.mark.asyncio
async def test_encoder_encode():
    """Encoder ì¸ì½”ë”© í…ŒìŠ¤íŠ¸"""
    encoder = JPEGEncoder()

    # í…ŒìŠ¤íŠ¸ RenderOutput ìƒì„±
    output = RenderOutput(
        color=torch.rand(480, 640, 3, dtype=torch.float32),
        depth=torch.rand(480, 640, dtype=torch.float32),
        alpha=torch.ones(480, 640, dtype=torch.float32),
        metadata={}
    )

    # ì¸ì½”ë”©
    payload = await encoder.encode(output, frame_id=42)

    # ê²€ì¦: RenderPayload êµ¬ì¡°
    assert isinstance(payload, RenderPayload), "Invalid payload type"
    assert payload.frame_id == 42, "Frame ID mismatch"
    assert isinstance(payload.metadata, dict), "Metadata must be dict"
    assert isinstance(payload.data, bytes), "Data must be bytes"

    # ê²€ì¦: Metadata
    assert payload.metadata["format_type"] == "jpeg+depth", \
        f"Format type mismatch: {payload.metadata['format_type']}"
    assert "color_len" in payload.metadata, "Missing color_len in metadata"
    assert "depth_len" in payload.metadata, "Missing depth_len in metadata"
    assert "width" in payload.metadata, "Missing width in metadata"
    assert "height" in payload.metadata, "Missing height in metadata"

    color_len = payload.metadata["color_len"]
    depth_len = payload.metadata["depth_len"]

    # ê²€ì¦: ë°ì´í„° í¬ê¸°
    assert color_len > 0, "Color JPEG is empty"
    assert depth_len == 640 * 480 * 2, \
        f"Depth size mismatch: expected {640*480*2}, got {depth_len}"  # float16

    # ê²€ì¦: ì „ì²´ ë°ì´í„° ê¸¸ì´
    assert len(payload.data) == color_len + depth_len, \
        f"Total data size mismatch: {len(payload.data)} != {color_len + depth_len}"

    print("âœ… Encoder ì¸ì½”ë”© ì„±ê³µ")
    print(f"   Format: {payload.metadata['format_type']}")
    print(f"   Color JPEG: {color_len} bytes")
    print(f"   Depth (float16): {depth_len} bytes")
    print(f"   Total: {len(payload.data)} bytes")
```

**ê²€ì¦ í•­ëª©:**
- [x] RenderPayload ìƒì„±
- [x] Frame ID ì¼ì¹˜
- [x] Metadata í¬í•¨: format_type, color_len, depth_len, width, height
- [x] JPEG ë°ì´í„° í¬ê¸° > 0
- [x] Depth ë°ì´í„° í¬ê¸° = W Ã— H Ã— 2 (float16)
- [x] ì „ì²´ ë°ì´í„° í¬ê¸° ì¼ì¹˜

---

### 5. E2E ë°ì´í„° íŒ¨ìŠ¤ í…ŒìŠ¤íŠ¸

**ëª©ì **: ì „ì²´ íŒŒì´í”„ë¼ì¸ì´ 1 í”„ë ˆì„ì„ ì •ìƒì ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ”ì§€ í™•ì¸

```python
# tests/test_e2e.py

import pytest
import asyncio
import struct
import websockets
import json

@pytest.mark.asyncio
@pytest.mark.timeout(20)
async def test_e2e_one_frame():
    """E2E 1 í”„ë ˆì„ ì „ì†¡ í…ŒìŠ¤íŠ¸"""

    # 1. Renderer Service ì‹œì‘ (Mock)
    renderer_ready = asyncio.Event()
    received_cameras = []

    async def mock_renderer():
        """Mock Renderer: Camera ìˆ˜ì‹  â†’ Video ì†¡ì‹ """
        # Camera ìˆ˜ì‹ 
        camera_reader, camera_writer = await asyncio.open_unix_connection(
            "/tmp/e2e_camera.sock"
        )

        renderer_ready.set()

        # Camera ë°ì´í„° ìˆ˜ì‹ 
        camera_data = await camera_reader.read(152)
        received_cameras.append(camera_data)

        # Mock ë Œë”ë§ ê²°ê³¼ ìƒì„±
        video_reader, video_writer = await asyncio.open_unix_connection(
            "/tmp/e2e_video.sock"
        )

        # RenderPayload ì „ì†¡
        metadata = {
            "format_type": "jpeg+depth",
            "color_len": 100,
            "depth_len": 200
        }
        metadata_bytes = json.dumps(metadata).encode('utf-8')
        test_data = b"mock_jpeg_data" + b"mock_depth_data"

        header = struct.pack("<QII", 99, len(metadata_bytes), len(test_data))
        video_writer.write(header + metadata_bytes + test_data)
        await video_writer.drain()

        video_writer.close()
        await video_writer.wait_closed()

    # 2. Transport Service ì‹œì‘
    transport_camera_queue = asyncio.Queue()

    async def transport_camera_server(reader, writer):
        """Transport: Camera ì¤‘ê³„"""
        data = await reader.read(152)
        await transport_camera_queue.put(data)

    async def transport_video_server(reader, writer):
        """Transport: Video ì¤‘ê³„"""
        # Rendererë¡œë¶€í„° ìˆ˜ì‹ 
        header = await reader.read(16)
        frame_id, meta_len, data_len = struct.unpack("<QII", header)

        metadata_bytes = await reader.read(meta_len)
        data = await reader.read(data_len)

        # Frontendë¡œ ì „ì†¡ (WebSocket ì‹œë®¬ë ˆì´ì…˜)
        # ì‹¤ì œë¡œëŠ” WebSocketAdapterê°€ ì²˜ë¦¬
        transport_video_server.payload = {
            "frame_id": frame_id,
            "metadata": json.loads(metadata_bytes),
            "data": data
        }

    transport_video_server.payload = None

    camera_server = await asyncio.start_unix_server(
        transport_camera_server, "/tmp/e2e_camera.sock"
    )
    video_server = await asyncio.start_unix_server(
        transport_video_server, "/tmp/e2e_video.sock"
    )

    await asyncio.sleep(0.5)

    # 3. Renderer ì‹œì‘
    renderer_task = asyncio.create_task(mock_renderer())

    # Renderer ì¤€ë¹„ ëŒ€ê¸°
    await asyncio.wait_for(renderer_ready.wait(), timeout=2.0)

    # 4. Frontend: Camera ì „ì†¡
    test_camera_data = b"C" * 152
    camera_reader, camera_writer = await asyncio.open_unix_connection(
        "/tmp/e2e_camera.sock"
    )
    camera_writer.write(test_camera_data)
    await camera_writer.drain()
    camera_writer.close()
    await camera_writer.wait_closed()

    # 5. ë°ì´í„° ì „íŒŒ ëŒ€ê¸°
    await asyncio.sleep(1.0)

    # 6. ê²€ì¦
    # Transportê°€ Camera ìˆ˜ì‹ í–ˆëŠ”ì§€
    assert transport_camera_queue.qsize() == 1, "Camera data not received by Transport"
    received = await transport_camera_queue.get()
    assert received == test_camera_data, "Camera data corrupted"

    # Rendererê°€ Camera ìˆ˜ì‹ í–ˆëŠ”ì§€
    assert len(received_cameras) == 1, "Renderer did not receive camera data"
    assert received_cameras[0] == test_camera_data, "Renderer received corrupted camera data"

    # Transportê°€ Video ìˆ˜ì‹ í–ˆëŠ”ì§€
    assert transport_video_server.payload is not None, "Transport did not receive video payload"
    assert transport_video_server.payload["frame_id"] == 99, "Frame ID mismatch"
    assert transport_video_server.payload["metadata"]["format_type"] == "jpeg+depth", \
        "Format type mismatch"

    # ì •ë¦¬
    renderer_task.cancel()
    camera_server.close()
    video_server.close()
    await camera_server.wait_closed()
    await video_server.wait_closed()

    print("âœ… E2E 1 í”„ë ˆì„ ì „ì†¡ ì„±ê³µ")
    print(f"   Frame ID: {transport_video_server.payload['frame_id']}")
    print(f"   Format: {transport_video_server.payload['metadata']['format_type']}")
```

**ê²€ì¦ í•­ëª©:**
- [x] Frontend â†’ Transport: Camera ì „ì†¡
- [x] Transport â†’ Renderer: Camera ì „ë‹¬
- [x] Renderer: ë Œë”ë§ ìˆ˜í–‰
- [x] Renderer â†’ Transport: Video ì „ì†¡
- [x] Transport â†’ Frontend: Video ì „ë‹¬
- [x] Frame ID ì¼ì¹˜
- [x] ë°ì´í„° ë¬´ê²°ì„±

---

## Phase 2: ì•ˆì •ì„± í…ŒìŠ¤íŠ¸

> **ëª©í‘œ**: ìš´ì˜ í™˜ê²½ì—ì„œ ì•ˆì •ì ìœ¼ë¡œ ë™ì‘
> **ì‹œê°„**: 1-2ì¼
> **í…ŒìŠ¤íŠ¸ ê°œìˆ˜**: 3ê°œ

### 6. ì˜ëª»ëœ ë°ì´í„° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸

**ëª©ì **: ì†ìƒë˜ê±°ë‚˜ ì˜ëª»ëœ ë°ì´í„°ë¥¼ ë°›ì•„ë„ í¬ë˜ì‹œí•˜ì§€ ì•ŠëŠ”ì§€ í™•ì¸

```python
@pytest.mark.asyncio
async def test_invalid_data_handling():
    """ì˜ëª»ëœ ë°ì´í„° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""

    # 1. ì˜ëª»ëœ í¬ê¸°ì˜ Camera ë°ì´í„°
    invalid_camera_data = b"x" * 100  # 152 bytes ì•„ë‹˜
    # â†’ ë¬´ì‹œí•˜ê³  ë¡œê·¸, í¬ë˜ì‹œ X

    # 2. ì†ìƒëœ Metadata
    corrupted_metadata = b"not_valid_json"
    # â†’ ì—ëŸ¬ ë¡œê·¸, í•´ë‹¹ í”„ë ˆì„ drop

    # 3. ê³¼ë„í•˜ê²Œ í° Payload
    oversized_data = b"x" * (100 * 1024 * 1024)  # 100 MB
    # â†’ ê±°ë¶€, ì—ëŸ¬ ë¡œê·¸
```

**ê²€ì¦ í•­ëª©:**
- [x] ì˜ëª»ëœ í¬ê¸° â†’ ë¬´ì‹œ
- [x] ì†ìƒëœ JSON â†’ ì—ëŸ¬ ë¡œê·¸, drop
- [x] ê³¼ë„í•œ í¬ê¸° â†’ ê±°ë¶€
- [x] í¬ë˜ì‹œ ì—†ìŒ

---

### 7. ì„±ëŠ¥ ëª©í‘œ ë‹¬ì„± í…ŒìŠ¤íŠ¸

**ëª©ì **: ì‹¤ì‹œê°„ ë Œë”ë§ ëª©í‘œ (60 FPS) ë‹¬ì„± í™•ì¸

```python
import time
import numpy as np

@pytest.mark.asyncio
async def test_render_latency_60fps():
    """ë Œë”ë§ ë ˆì´í„´ì‹œ ëª©í‘œ ë‹¬ì„± í…ŒìŠ¤íŠ¸"""
    renderer = GaussianSplattingRenderer("test/fixtures/scenes/test_scene.ply")
    await renderer.on_init()

    camera = create_test_camera_frame()

    # 100 í”„ë ˆì„ ë Œë”ë§
    latencies = []
    for _ in range(100):
        start = time.perf_counter()
        output = await renderer.render(camera)
        end = time.perf_counter()
        latencies.append((end - start) * 1000)  # ms

    avg_latency = np.mean(latencies)
    p95_latency = np.percentile(latencies, 95)

    print(f"Render Latency: Avg={avg_latency:.2f}ms, P95={p95_latency:.2f}ms")

    # ëª©í‘œ: 60 FPS = 16.67 ms/frame
    assert avg_latency < 16.67, f"Too slow: {avg_latency:.2f}ms"

    await renderer.on_shutdown()
```

**ê²€ì¦ í•­ëª©:**
- [x] í‰ê·  ë Œë”ë§ ì‹œê°„ < 16.67ms (60 FPS)
- [x] P95 ë ˆì´í„´ì‹œ ì¸¡ì •
- [x] E2E ë ˆì´í„´ì‹œ < 50ms

---

### 8. ë‹¤ì¤‘ Frontend ì²˜ë¦¬ í…ŒìŠ¤íŠ¸

**ëª©ì **: ì—¬ëŸ¬ Frontendê°€ ë™ì‹œì— ì—°ê²°ë˜ì–´ë„ ì •ìƒ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸

```python
@pytest.mark.asyncio
async def test_multiple_frontends():
    """ë‹¤ì¤‘ Frontend ë™ì‹œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    transport = TransportCore()

    # 3ê°œ Frontend ì—°ê²°
    received_payloads = [[], [], []]

    class MockFrontendAdapter:
        def __init__(self, index):
            self.index = index

        async def send(self, payload):
            received_payloads[self.index].append(payload)

    for i in range(3):
        transport.add_frontend_adapter(MockFrontendAdapter(i))

    # Payload ë¸Œë¡œë“œìºìŠ¤íŠ¸
    payload = create_test_payload(frame_id=10)
    await transport.broadcast_to_frontends(payload)

    # ëª¨ë“  Frontendê°€ ë°›ì•˜ëŠ”ì§€ í™•ì¸
    for i in range(3):
        assert len(received_payloads[i]) == 1
        assert received_payloads[i][0].frame_id == 10

    print("âœ… 3ê°œ Frontend ëª¨ë‘ ë™ì¼í•œ í”„ë ˆì„ ìˆ˜ì‹ ")
```

**ê²€ì¦ í•­ëª©:**
- [x] 2-3ê°œ Frontend ë™ì‹œ ì—°ê²°
- [x] ëª¨ë‘ ë™ì¼í•œ í”„ë ˆì„ ìˆ˜ì‹ 
- [x] Frame ID ì¼ì¹˜

---

## Phase 3: ì¶”ê°€ í…ŒìŠ¤íŠ¸

> **ëª©í‘œ**: ì—£ì§€ ì¼€ì´ìŠ¤ ëŒ€ì‘
> **ì‹œê°„**: 1ì¼
> **í…ŒìŠ¤íŠ¸ ê°œìˆ˜**: 2ê°œ

### 9. Queue Overflow í…ŒìŠ¤íŠ¸

**ëª©ì **: Queueê°€ ê½‰ ì°¼ì„ ë•Œ ì²˜ë¦¬

```python
@pytest.mark.asyncio
async def test_camera_queue_overflow():
    """Camera Queue ì˜¤ë²„í”Œë¡œìš° ì²˜ë¦¬"""
    queue = asyncio.Queue(maxsize=2)

    # Queue ê°€ë“ ì±„ìš°ê¸°
    await queue.put("frame1")
    await queue.put("frame2")

    # ìƒˆ í”„ë ˆì„ ì¶”ê°€ ì‹œë„
    # â†’ ê°€ì¥ ì˜¤ë˜ëœ í”„ë ˆì„ drop, ìƒˆ í”„ë ˆì„ ì¶”ê°€

    assert queue.qsize() == 2
```

**ê²€ì¦ í•­ëª©:**
- [x] Queue full â†’ ê°€ì¥ ì˜¤ë˜ëœ í”„ë ˆì„ drop
- [x] í¬ë˜ì‹œ ì—†ìŒ

---

### 10. GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì²˜ë¦¬

**ëª©ì **: í° Scene ë¡œë“œ ì‹œ OOM ì²˜ë¦¬

```python
@pytest.mark.asyncio
async def test_gpu_oom_handling():
    """GPU OOM ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    # ë§¤ìš° í° Scene ë¡œë“œ ì‹œë„
    renderer = GaussianSplattingRenderer("huge_scene.ply")

    try:
        await renderer.on_init()
    except torch.cuda.OutOfMemoryError:
        # ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥
        print("GPU ë©”ëª¨ë¦¬ ë¶€ì¡±: Sceneì´ ë„ˆë¬´ í½ë‹ˆë‹¤")
        # Graceful exit
        return

    # OOMì´ ë°œìƒí•´ì•¼ í•¨
    assert False, "Expected OOM error"
```

**ê²€ì¦ í•­ëª©:**
- [x] OOM ë°œìƒ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€
- [x] Graceful exit

---

## Phase 4: í›„ìˆœìœ„ (ìš´ì˜ ì¤‘ ì¶”ê°€)

> ë‹¹ì¥ êµ¬í˜„í•˜ì§€ ì•Šì•„ë„ ë˜ì§€ë§Œ, ìš´ì˜ ì¤‘ í•„ìš”ì‹œ ì¶”ê°€

### ì¬ì—°ê²° ê´€ë ¨

- `test_renderer_disconnect_reconnect()` - ì„œë²„ ì¬ì‹œì‘ìœ¼ë¡œ ëŒ€ì²´ ê°€ëŠ¥
- `test_transport_crash_recovery()` - ì„œë²„ ì¬ì‹œì‘ìœ¼ë¡œ ëŒ€ì²´ ê°€ëŠ¥

### ì¥ì‹œê°„ ì•ˆì •ì„±

- `test_1000_frames_stability()` - ìš´ì˜ ì¤‘ ëª¨ë‹ˆí„°ë§ìœ¼ë¡œ ëŒ€ì²´
- `test_24hour_stability()` - ìš´ì˜ ì¤‘ í™•ì¸

### ë³´ì•ˆ

- `test_socket_file_permissions()` - Docker í™˜ê²½ì—ì„œ ìë™ ì„¤ì •
- `test_unauthorized_access()` - ë¡œì»¬ í™˜ê²½ì´ë¯€ë¡œ ë‚®ì€ ìš°ì„ ìˆœìœ„

### ê¸°íƒ€

- `test_different_resolutions()` - í•„ìš”ì‹œ ì¶”ê°€
- `test_protocol_version_compatibility()` - ë²„ì „ ê´€ë¦¬ ì‹œì‘ í›„ ì¶”ê°€

---

## í…ŒìŠ¤íŠ¸ ì‹¤í–‰

### ë¡œì»¬ ì‹¤í–‰

```bash
# Phase 1: MVP í•„ìˆ˜ í…ŒìŠ¤íŠ¸
pytest tests/test_mvp/ -v

# Phase 2: ì•ˆì •ì„± í…ŒìŠ¤íŠ¸
pytest tests/test_stability/ -v

# ì „ì²´ í…ŒìŠ¤íŠ¸
pytest -v

# íŠ¹ì • í…ŒìŠ¤íŠ¸
pytest tests/test_e2e.py::test_e2e_one_frame -v

# ì»¤ë²„ë¦¬ì§€ ì¸¡ì •
pytest --cov=renderer --cov=transport --cov-report=html
```

### Docker ì‹¤í–‰

```bash
# Docker Composeë¡œ í†µí•© í…ŒìŠ¤íŠ¸
docker-compose -f docker-compose.test.yml up --abort-on-container-exit

# ê°œë³„ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸
docker-compose -f docker-compose.test.yml run renderer pytest
```

---

## í…ŒìŠ¤íŠ¸ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 1: MVP í•„ìˆ˜

- [ ] 1. Unix Socket ìƒì„±
  - [ ] `/run/ipc/camera.sock` ì¡´ì¬
  - [ ] `/run/ipc/video.sock` ì¡´ì¬
  - [ ] Socket íƒ€ì… í™•ì¸

- [ ] 2. Socket ì—°ê²° (ì–‘ë°©í–¥)
  - [ ] Transport â†’ Renderer: Camera ì „ì†¡
  - [ ] Renderer â†’ Transport: Video ìˆ˜ì‹ 
  - [ ] ë°ì´í„° ë¬´ê²°ì„±

- [ ] 3. Scene Renderer
  - [ ] ì´ˆê¸°í™” ì„±ê³µ
  - [ ] RenderOutput ìƒì„±
  - [ ] Shape, dtype ê²€ì¦
  - [ ] ê°’ ë²”ìœ„ ê²€ì¦

- [ ] 4. Encoder
  - [ ] RenderPayload ìƒì„±
  - [ ] Metadata í¬í•¨
  - [ ] ë°ì´í„° í¬ê¸° ê²€ì¦

- [ ] 5. E2E ë°ì´í„° íŒ¨ìŠ¤
  - [ ] 1 í”„ë ˆì„ ì™„ì „ ì „ì†¡
  - [ ] Frame ID ì¼ì¹˜
  - [ ] ì „ì²´ íë¦„ ë™ì‘

### Phase 2: ì•ˆì •ì„±

- [ ] 6. ì˜ëª»ëœ ë°ì´í„° ì²˜ë¦¬
  - [ ] ì˜ëª»ëœ í¬ê¸° ì²˜ë¦¬
  - [ ] ì†ìƒëœ ë°ì´í„° ì²˜ë¦¬
  - [ ] í¬ë˜ì‹œ ì—†ìŒ

- [ ] 7. ì„±ëŠ¥ ëª©í‘œ
  - [ ] ë Œë”ë§ < 16.67ms
  - [ ] E2E < 50ms

- [ ] 8. ë‹¤ì¤‘ Frontend
  - [ ] 2-3ê°œ ë™ì‹œ ì—°ê²°
  - [ ] ëª¨ë‘ ìˆ˜ì‹  í™•ì¸

### Phase 3: ì¶”ê°€

- [ ] 9. Queue Overflow
- [ ] 10. GPU OOM ì²˜ë¦¬

---

## í…ŒìŠ¤íŠ¸ ìš°ì„ ìˆœìœ„ ìš”ì•½

| Phase | ëª©í‘œ | í…ŒìŠ¤íŠ¸ ê°œìˆ˜ | ì˜ˆìƒ ì‹œê°„ | ì¤‘ìš”ë„ |
|-------|------|------------|----------|--------|
| Phase 1 | MVP í•„ìˆ˜ | 5 | 2-3ì¼ | â­â­â­ |
| Phase 2 | ì•ˆì •ì„± | 3 | 1-2ì¼ | â­â­ |
| Phase 3 | ì¶”ê°€ | 2 | 1ì¼ | â­ |
| Phase 4 | í›„ìˆœìœ„ | - | ìš´ì˜ ì¤‘ | - |

**ì´ 10ê°œ í•µì‹¬ í…ŒìŠ¤íŠ¸ë¡œ íŒŒì´í”„ë¼ì¸ ê²€ì¦ ì™„ë£Œ**

---

## ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜

í…ŒìŠ¤íŠ¸ì— ì‚¬ìš©ë˜ëŠ” ê³µí†µ ìœ í‹¸ë¦¬í‹°:

```python
# tests/utils.py

import numpy as np
import torch
from data_types import CameraFrame, RenderOutput, RenderPayload

def create_test_camera_frame(frame_id=1, width=640, height=480):
    """í…ŒìŠ¤íŠ¸ìš© CameraFrame ìƒì„±"""
    return CameraFrame(
        view_matrix=np.eye(4, dtype=np.float32),
        intrinsics=create_test_intrinsics(width, height),
        time_index=0.0,
        frame_id=frame_id,
        client_timestamp=0.0,
        server_timestamp=0.0
    )

def create_test_intrinsics(width, height, fov=60):
    """í…ŒìŠ¤íŠ¸ìš© Intrinsics ìƒì„±"""
    focal_length = width / (2 * np.tan(np.radians(fov) / 2))
    return np.array([
        [focal_length, 0, width / 2, 0],
        [0, focal_length, height / 2, 0],
        [0, 0, 1, 0],
        [0, 0, 0, 1]
    ], dtype=np.float32)

def create_test_render_output(width=640, height=480):
    """í…ŒìŠ¤íŠ¸ìš© RenderOutput ìƒì„±"""
    return RenderOutput(
        color=torch.rand(height, width, 3, dtype=torch.float32),
        depth=torch.rand(height, width, dtype=torch.float32),
        alpha=torch.ones(height, width, dtype=torch.float32),
        metadata={}
    )

def create_test_payload(frame_id=1):
    """í…ŒìŠ¤íŠ¸ìš© RenderPayload ìƒì„±"""
    return RenderPayload(
        frame_id=frame_id,
        metadata={
            "format_type": "jpeg+depth",
            "color_len": 100,
            "depth_len": 200
        },
        data=b"test_data"
    )
```

---

## í…ŒìŠ¤íŠ¸ í”½ìŠ¤ì²˜ ìƒì„± ê°€ì´ë“œ

### Minimal Scene ìƒì„±

í…ŒìŠ¤íŠ¸ìš© ìµœì†Œ Gaussian Scene (.ply íŒŒì¼) ìƒì„±:

```python
# scripts/create_test_fixtures.py

import numpy as np
import struct

def create_minimal_ply(output_path="tests/fixtures/scenes/minimal_scene.ply", num_points=10):
    """
    ìµœì†Œ Gaussian Scene ìƒì„± (10 gaussians)

    ê° Gaussianì€ ë‹¤ìŒì„ í¬í•¨:
    - xyz: ìœ„ì¹˜ (3 floats)
    - normals: ë²•ì„  (3 floats, ì‚¬ìš© ì•ˆ í•¨)
    - f_dc_0, f_dc_1, f_dc_2: SH ê³„ìˆ˜ (3 floats)
    - opacity: ë¶ˆíˆ¬ëª…ë„ (1 float)
    - scale_0, scale_1, scale_2: ìŠ¤ì¼€ì¼ (3 floats)
    - rot_0, rot_1, rot_2, rot_3: íšŒì „ (4 floats)
    """
    # Random gaussians in unit cube
    np.random.seed(42)

    positions = np.random.rand(num_points, 3) * 2 - 1  # [-1, 1]
    normals = np.zeros((num_points, 3))  # Not used
    sh_dc = np.ones((num_points, 3)) * 0.5  # Gray color
    opacity = np.ones(num_points) * 0.9  # 90% opaque
    scale = np.ones((num_points, 3)) * 0.01  # Small gaussians
    rotation = np.zeros((num_points, 4))  # Identity quaternion
    rotation[:, 0] = 1.0

    # PLY header
    header = f"""ply
format binary_little_endian 1.0
element vertex {num_points}
property float x
property float y
property float z
property float nx
property float ny
property float nz
property float f_dc_0
property float f_dc_1
property float f_dc_2
property float opacity
property float scale_0
property float scale_1
property float scale_2
property float rot_0
property float rot_1
property float rot_2
property float rot_3
end_header
"""

    # Write PLY file
    with open(output_path, 'wb') as f:
        f.write(header.encode('utf-8'))

        for i in range(num_points):
            # Pack all properties for this gaussian
            data = struct.pack('<17f',
                positions[i, 0], positions[i, 1], positions[i, 2],
                normals[i, 0], normals[i, 1], normals[i, 2],
                sh_dc[i, 0], sh_dc[i, 1], sh_dc[i, 2],
                opacity[i],
                scale[i, 0], scale[i, 1], scale[i, 2],
                rotation[i, 0], rotation[i, 1], rotation[i, 2], rotation[i, 3]
            )
            f.write(data)

    print(f"âœ… Created minimal scene: {output_path} ({num_points} gaussians)")


def create_camera_frame_fixture(output_path="tests/fixtures/expected/camera_frame_001.bin"):
    """152 bytes camera frame ìƒ˜í”Œ ìƒì„±"""
    view_matrix = np.eye(4, dtype=np.float32)
    intrinsics = create_test_intrinsics(640, 480)

    camera = CameraFrame(
        view_matrix=view_matrix,
        intrinsics=intrinsics,
        time_index=0.0,
        frame_id=1,
        client_timestamp=1000.0,
        server_timestamp=1001.0
    )

    data = pack_camera_frame(camera)
    assert len(data) == 152, f"Invalid camera frame size: {len(data)}"

    with open(output_path, 'wb') as f:
        f.write(data)

    print(f"âœ… Created camera frame fixture: {output_path} (152 bytes)")


if __name__ == "__main__":
    import os
    os.makedirs("tests/fixtures/scenes", exist_ok=True)
    os.makedirs("tests/fixtures/expected", exist_ok=True)

    create_minimal_ply()
    create_camera_frame_fixture()
```

**ì‹¤í–‰:**
```bash
python scripts/create_test_fixtures.py
```

---

## Mock ê°ì²´ êµ¬í˜„

### Mock Scene Renderer

```python
# tests/mocks/mock_renderer.py

import torch
import asyncio
from renderer.scene_renderers.base import BaseSceneRenderer
from renderer.data_types import CameraFrame, RenderOutput

class MockSceneRenderer(BaseSceneRenderer):
    """í…ŒìŠ¤íŠ¸ìš© Mock Renderer (ë¹ ë¥¸ ì‹¤í–‰)"""

    def __init__(self, width=640, height=480, init_delay=0.0, render_delay=0.001):
        self.width = width
        self.height = height
        self.init_delay = init_delay
        self.render_delay = render_delay
        self.initialized = False
        self.render_count = 0

    async def on_init(self) -> bool:
        """ì´ˆê¸°í™” ì‹œë®¬ë ˆì´ì…˜"""
        if self.init_delay > 0:
            await asyncio.sleep(self.init_delay)

        self.initialized = True
        print(f"MockRenderer initialized ({self.width}x{self.height})")
        return True

    async def render(self, camera: CameraFrame) -> RenderOutput:
        """ê°€ì§œ ë Œë”ë§ (ê³ ì •ëœ íŒ¨í„´)"""
        if not self.initialized:
            raise RuntimeError("Renderer not initialized")

        if self.render_delay > 0:
            await asyncio.sleep(self.render_delay)

        # ê³ ì •ëœ íŒ¨í„´ ìƒì„± (ì²´í¬ë³´ë“œ)
        color = torch.zeros(self.height, self.width, 3, dtype=torch.float32)
        color[::2, ::2, :] = 1.0  # White squares
        color[1::2, 1::2, :] = 1.0

        depth = torch.ones(self.height, self.width, dtype=torch.float32) * 5.0
        alpha = torch.ones(self.height, self.width, dtype=torch.float32)

        self.render_count += 1

        return RenderOutput(
            color=color,
            depth=depth,
            alpha=alpha,
            metadata={"renderer": "mock", "frame_id": camera.frame_id}
        )

    async def on_shutdown(self):
        """ì¢…ë£Œ ì‹œë®¬ë ˆì´ì…˜"""
        self.initialized = False
        print(f"MockRenderer shutdown (rendered {self.render_count} frames)")
```

### Mock Encoder

```python
# tests/mocks/mock_encoder.py

from renderer.encoders.base import BaseEncoder
from renderer.data_types import RenderOutput, RenderPayload

class MockEncoder(BaseEncoder):
    """í…ŒìŠ¤íŠ¸ìš© Mock Encoder (ì‹¤ì œ ì¸ì½”ë”© ì—†ìŒ)"""

    def __init__(self, format_type="mock"):
        self.format_type = format_type
        self.encode_count = 0

    def get_format_type(self) -> str:
        return self.format_type

    async def encode(self, output: RenderOutput, frame_id: int) -> RenderPayload:
        """ê°€ì§œ ì¸ì½”ë”© (ê³ ì •ëœ ë°ì´í„°)"""
        self.encode_count += 1

        # ê³ ì •ëœ payload
        metadata = {
            "format_type": self.format_type,
            "width": output.color.shape[1],
            "height": output.color.shape[0],
            "color_len": 100,
            "depth_len": 200
        }

        data = b"MOCK_COLOR_DATA" + b"MOCK_DEPTH_DATA"

        return RenderPayload(
            frame_id=frame_id,
            metadata=metadata,
            data=data
        )
```

### Mock Transport (Unix Socket ì‹œë®¬ë ˆì´ì…˜)

```python
# tests/mocks/mock_transport.py

import asyncio
import struct
import json
from collections import deque

class MockTransport:
    """í…ŒìŠ¤íŠ¸ìš© Mock Transport (Unix Socket ì—†ì´)"""

    def __init__(self):
        self.camera_queue = asyncio.Queue()
        self.video_queue = asyncio.Queue()
        self.received_cameras = []
        self.sent_videos = []

    async def send_camera(self, camera: CameraFrame):
        """Frontend â†’ Transport: Camera ì „ì†¡ ì‹œë®¬ë ˆì´ì…˜"""
        data = pack_camera_frame(camera)
        await self.camera_queue.put(data)
        self.received_cameras.append(camera)

    async def receive_camera(self) -> bytes:
        """Transport â†’ Renderer: Camera ìˆ˜ì‹  ì‹œë®¬ë ˆì´ì…˜"""
        return await self.camera_queue.get()

    async def send_video(self, payload: RenderPayload):
        """Renderer â†’ Transport: Video ì „ì†¡ ì‹œë®¬ë ˆì´ì…˜"""
        data = pack_render_payload(payload)
        await self.video_queue.put(data)
        self.sent_videos.append(payload)

    async def receive_video(self) -> RenderPayload:
        """Transport â†’ Frontend: Video ìˆ˜ì‹  ì‹œë®¬ë ˆì´ì…˜"""
        data = await self.video_queue.get()

        # Parse wire format
        header = data[:16]
        frame_id, meta_len, data_len = struct.unpack("<QII", header)

        offset = 16
        metadata_bytes = data[offset:offset+meta_len]
        metadata = json.loads(metadata_bytes)

        offset += meta_len
        payload_data = data[offset:offset+data_len]

        return RenderPayload(
            frame_id=frame_id,
            metadata=metadata,
            data=payload_data
        )
```

**ì‚¬ìš© ì˜ˆì‹œ:**
```python
@pytest.mark.asyncio
async def test_with_mocks():
    """Mock ê°ì²´ë¥¼ ì‚¬ìš©í•œ í…ŒìŠ¤íŠ¸"""
    # Mock renderer & encoder
    renderer = MockSceneRenderer(width=640, height=480)
    encoder = MockEncoder()

    await renderer.on_init()

    # Test render
    camera = create_test_camera_frame(frame_id=1)
    output = await renderer.render(camera)

    assert output.color.shape == (480, 640, 3)

    # Test encode
    payload = await encoder.encode(output, frame_id=1)

    assert payload.frame_id == 1
    assert payload.metadata["format_type"] == "mock"

    await renderer.on_shutdown()
```

---

## CI/CD í†µí•©

### GitHub Actions ì„¤ì •

```yaml
# .github/workflows/test.yml

name: Test Pipeline

on:
  push:
    branches: [ main, develop, feature-* ]
  pull_request:
    branches: [ main ]

jobs:
  test-renderer:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        cd renderer
        pip install -r requirements.txt
        pip install pytest pytest-asyncio pytest-timeout pytest-cov

    - name: Create test fixtures
      run: |
        python scripts/create_test_fixtures.py

    - name: Run Phase 1 tests (MVP)
      run: |
        cd renderer
        pytest tests/test_mvp/ -v --tb=short

    - name: Run Phase 2 tests (Stability)
      run: |
        cd renderer
        pytest tests/test_stability/ -v --tb=short

    - name: Generate coverage report
      run: |
        cd renderer
        pytest --cov=. --cov-report=xml --cov-report=html

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./renderer/coverage.xml

  test-integration:
    runs-on: ubuntu-latest
    needs: test-renderer

    services:
      # Docker Composeë¡œ í†µí•© í…ŒìŠ¤íŠ¸
      transport:
        image: hybrid-transport:test
      renderer:
        image: hybrid-renderer:test

    steps:
    - uses: actions/checkout@v3

    - name: Run E2E tests
      run: |
        pytest tests/test_e2e.py -v --timeout=60
```

### Docker Compose Test ì„¤ì •

```yaml
# docker-compose.test.yml

version: '3.8'

services:
  transport-test:
    build:
      context: ./transport
      dockerfile: Dockerfile.test
    volumes:
      - ipc-sockets:/run/ipc
    networks:
      - test-net

  renderer-test:
    build:
      context: ./renderer
      dockerfile: Dockerfile.test
    volumes:
      - ipc-sockets:/run/ipc
      - ./tests/fixtures:/fixtures
    networks:
      - test-net
    depends_on:
      - transport-test

  test-runner:
    build:
      context: ./tests
      dockerfile: Dockerfile
    volumes:
      - ipc-sockets:/run/ipc
      - ./tests:/tests
    networks:
      - test-net
    depends_on:
      - transport-test
      - renderer-test
    command: pytest /tests -v

volumes:
  ipc-sockets:

networks:
  test-net:
```

**ì‹¤í–‰:**
```bash
docker-compose -f docker-compose.test.yml up --abort-on-container-exit
```

---

## ì»¤ë²„ë¦¬ì§€ ì¸¡ì •

### pytest-cov ì„¤ì •

```ini
# renderer/pytest.ini

[pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ ì§€ì›
asyncio_mode = auto

# Timeout ì„¤ì • (ê¸°ë³¸ 10ì´ˆ)
timeout = 10

# ì»¤ë²„ë¦¬ì§€ ì„¤ì •
addopts =
    --cov=renderer
    --cov-report=term-missing
    --cov-report=html:htmlcov
    --cov-report=xml
    --cov-fail-under=80
    -v
    --tb=short

# ì»¤ë²„ë¦¬ì§€ ì œì™¸ ê²½ë¡œ
[coverage:run]
omit =
    */tests/*
    */scene_renderers/external/*
    setup.py

[coverage:report]
exclude_lines =
    pragma: no cover
    def __repr__
    raise AssertionError
    raise NotImplementedError
    if __name__ == .__main__.:
    if TYPE_CHECKING:
```

### ì»¤ë²„ë¦¬ì§€ ì‹¤í–‰

```bash
# ì „ì²´ í…ŒìŠ¤íŠ¸ + ì»¤ë²„ë¦¬ì§€
pytest --cov=renderer --cov-report=html

# HTML ë¦¬í¬íŠ¸ ì—´ê¸°
open htmlcov/index.html

# íŠ¹ì • ëª¨ë“ˆ ì»¤ë²„ë¦¬ì§€
pytest --cov=renderer.scene_renderers --cov-report=term-missing

# ìµœì†Œ ì»¤ë²„ë¦¬ì§€ ê²€ì¦ (80% ë¯¸ë§Œ ì‹œ ì‹¤íŒ¨)
pytest --cov=renderer --cov-fail-under=80
```

### ì»¤ë²„ë¦¬ì§€ ëª©í‘œ

| ëª¨ë“ˆ | ëª©í‘œ ì»¤ë²„ë¦¬ì§€ | ìš°ì„ ìˆœìœ„ |
|------|--------------|----------|
| `data_types.py` | 100% | â­â­â­ |
| `utils/protocol.py` | 100% | â­â­â­ |
| `renderer_service.py` | 90% | â­â­â­ |
| `scene_renderers/base.py` | 100% | â­â­â­ |
| `encoders/base.py` | 100% | â­â­â­ |
| `scene_renderers/gaussian_splatting.py` | 80% | â­â­ |
| `encoders/jpeg.py` | 80% | â­â­ |
| **ì „ì²´** | **80%+** | â­â­â­ |

---

## Docker í…ŒìŠ¤íŠ¸ í™˜ê²½

### Renderer Test Dockerfile

```dockerfile
# renderer/Dockerfile.test

FROM nvidia/cuda:12.1.0-devel-ubuntu22.04

# Python ì„¤ì¹˜
RUN apt-get update && apt-get install -y \
    python3.10 \
    python3-pip \
    git

# PyTorch ì„¤ì¹˜
RUN pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# í…ŒìŠ¤íŠ¸ ì˜ì¡´ì„±
COPY requirements.txt requirements-test.txt ./
RUN pip3 install -r requirements.txt -r requirements-test.txt

# ì½”ë“œ ë³µì‚¬
COPY . /app
WORKDIR /app

# Unix socket ë””ë ‰í† ë¦¬
RUN mkdir -p /run/ipc

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
CMD ["pytest", "tests/", "-v"]
```

### requirements-test.txt

```
# renderer/requirements-test.txt

pytest>=7.4.0
pytest-asyncio>=0.21.0
pytest-timeout>=2.1.0
pytest-cov>=4.1.0
pytest-mock>=3.11.0

# Mock ë„êµ¬
faker>=19.0.0

# ì½”ë“œ í’ˆì§ˆ
black>=23.7.0
flake8>=6.0.0
mypy>=1.4.0
```

### í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# scripts/run_tests.sh

set -e

echo "ğŸ§ª Running HybridPipeline Tests"

# 1. í…ŒìŠ¤íŠ¸ í”½ìŠ¤ì²˜ ìƒì„±
echo "ğŸ“¦ Creating test fixtures..."
python scripts/create_test_fixtures.py

# 2. Phase 1 í…ŒìŠ¤íŠ¸ (MVP)
echo "ğŸ¯ Phase 1: MVP Tests"
pytest tests/test_mvp/ -v --tb=short

# 3. Phase 2 í…ŒìŠ¤íŠ¸ (ì•ˆì •ì„±)
echo "ğŸ›¡ï¸  Phase 2: Stability Tests"
pytest tests/test_stability/ -v --tb=short

# 4. ì»¤ë²„ë¦¬ì§€ ì¸¡ì •
echo "ğŸ“Š Generating coverage report..."
pytest --cov=renderer --cov-report=html --cov-report=term

# 5. ì½”ë“œ í’ˆì§ˆ ì²´í¬
echo "âœ¨ Code quality checks..."
black renderer/ --check
flake8 renderer/ --max-line-length=100
mypy renderer/ --ignore-missing-imports

echo "âœ… All tests passed!"
```

**ì‹¤í–‰:**
```bash
chmod +x scripts/run_tests.sh
./scripts/run_tests.sh
```

---

## í…ŒìŠ¤íŠ¸ ë””ë²„ê¹… íŒ

### 1. ê°œë³„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# íŠ¹ì • í…ŒìŠ¤íŠ¸ íŒŒì¼
pytest tests/test_encoder.py -v

# íŠ¹ì • í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
pytest tests/test_encoder.py::test_encoder_encode -v

# íŠ¹ì • í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤
pytest tests/test_encoder.py::TestJPEGEncoder -v
```

### 2. ìƒì„¸ ì¶œë ¥

```bash
# ì „ì²´ traceback ì¶œë ¥
pytest -v --tb=long

# print ë¬¸ ì¶œë ¥ ë³´ê¸°
pytest -v -s

# ë¡œê·¸ ì¶œë ¥ ë³´ê¸°
pytest -v --log-cli-level=DEBUG
```

### 3. ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ ì¤‘ë‹¨

```bash
# ì²« ë²ˆì§¸ ì‹¤íŒ¨ì—ì„œ ì¤‘ë‹¨
pytest -x

# 3ë²ˆ ì‹¤íŒ¨ í›„ ì¤‘ë‹¨
pytest --maxfail=3
```

### 4. ë§ˆì§€ë§‰ ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ë§Œ ì¬ì‹¤í–‰

```bash
# ë§ˆì§€ë§‰ ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ë§Œ
pytest --lf

# ë§ˆì§€ë§‰ ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ ë¨¼ì €, ê·¸ ë‹¤ìŒ ë‚˜ë¨¸ì§€
pytest --ff
```

### 5. ë””ë²„ê±° ì‚¬ìš©

```bash
# ì‹¤íŒ¨ ì‹œ pdb ì‹œì‘
pytest --pdb

# íŠ¹ì • ìœ„ì¹˜ì— breakpoint()
# í…ŒìŠ¤íŠ¸ ì½”ë“œì— breakpoint() ì¶”ê°€ í›„
pytest tests/test_encoder.py -v
```

---

## ë‹¤ìŒ ë‹¨ê³„

1. âœ… **Phase 1 í…ŒìŠ¤íŠ¸ êµ¬í˜„** (MVP í•„ìˆ˜ 5ê°œ)
2. âœ… **CI/CD ì„¤ì •** (GitHub Actions)
3. âœ… **Phase 2 í…ŒìŠ¤íŠ¸ ì¶”ê°€** (ì•ˆì •ì„± 3ê°œ)
4. âœ… **ì»¤ë²„ë¦¬ì§€ 80% ëª©í‘œ**
5. ìš´ì˜ ì¤‘ Phase 3, 4 í•„ìš”ì‹œ ì¶”ê°€

**í…ŒìŠ¤íŠ¸ ì£¼ë„ë¡œ ì•ˆì •ì ì¸ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•!** ğŸš€
